from fastapi import APIRouter, Request, UploadFile, File, BackgroundTasks
from starlette.background import BackgroundTask
from fastapi.responses import FileResponse
from fastapi.responses import JSONResponse
import os, httpx, csv, psutil, struct, tempfile
import ujson as json
import shutil, logging, subprocess, asyncio
from datetime import datetime
from states.global_state import influx_state, redis_state, aesState,os_spec
from collections import defaultdict
from typing import Dict, Any, List
from routes.util import get_mac_address, sysService, is_service_active, getVersions, saveLog, get_lastpost, Post, save_post, WAVEFORM_PATHS
from routes.api import parameter_options
from .RedisBinary import Command, CmdType, ItemType
import pyinotify, threading
import asyncio, time

import sqlite3

# Path ê°ì²´ ì ˆëŒ€ê²½ë¡œ
from pathlib import Path
base_dir = Path(__file__).resolve().parent
SETTING_FOLDER = base_dir.parent.parent / "config"  # â¬…ï¸ ë‘ ë‹¨ê³„ ìƒìœ„ë¡œ
BEARINGDB_PATH = SETTING_FOLDER / "bearing.db"
setting_timeout = httpx.Timeout(
    connect=2.0,  # ì—°ê²°ì—ëŠ” 5ì´ˆ
    read=30.0,     # ì‘ë‹µ ì½ê¸°ëŠ” 2ì´ˆ
    write=2.0,    # ìš”ì²­ ì „ì†¡ì€ 5ì´ˆ
    pool=5.0      # ì—°ê²° í’€ì€ 5ì´ˆ
)

router = APIRouter()

def command_to_binary(command: Command) -> bytes:
    """Command ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜ (C êµ¬ì¡°ì²´ì™€ í˜¸í™˜)"""
    # Cì˜ intëŠ” ë³´í†µ 4ë°”ì´íŠ¸, enumë„ intë¡œ ì²˜ë¦¬
    # êµ¬ì¡°: int(4) + int(4) + int(4) = 12 bytes
    return struct.pack('iii', command.type, command.cmd, command.item)


def binary_to_command(binary_data: bytes) -> Command:
    """ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ Command ê°ì²´ë¡œ ë³€í™˜"""
    if len(binary_data) != 12:
        raise ValueError("Invalid binary data size")

    type_val, cmd_val, item_val = struct.unpack('iii', binary_data)
    return Command(type=type_val, cmd=CmdType(cmd_val), item=ItemType(item_val))


def read_mac_plain(filepath):
    """íŒŒì¼ì—ì„œ MAC ì£¼ì†Œë¥¼ êµ¬ë¶„ì ì—†ì´ ì½ê¸°"""
    with open(filepath, 'rb') as f:
        mac_bytes = f.read(6)

        if len(mac_bytes) != 6:
            raise ValueError(f"ì˜ëª»ëœ MAC ì£¼ì†Œ ê¸¸ì´: {len(mac_bytes)} bytes")

        # êµ¬ë¶„ì ì—†ì´ ë°˜í™˜
        return mac_bytes.hex().lower()  # ë” ê°„ë‹¨í•œ ë°©ë²•

@router.get('/getMac')
def getMacAddr():
    devMac = get_mac_address()
    return {'success':True, 'mac': devMac}

@router.get('/checkInitDB')
async def checkInitDB():
    file_path = os.path.join(SETTING_FOLDER, 'influx.json')
    if not os.path.exists(file_path):
        return {'result': False}
    else:
        return {'result': True}


@router.get('/initDB')
async def initInflux(background_tasks: BackgroundTasks):
    file_path = os.path.join(SETTING_FOLDER, 'influx.json')
    data = {
        "username": "admin",
        "password": "ntek9135",
        "org": "ntek",
        "bucket": "nteks",
        "retentionPeriodSeconds": 0
    }
    try:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(f"http://127.0.0.1:8086/api/v2/setup", json=data)
            resData = response.json()
            if resData.get("code") == "conflict":
                logging.warning("âš ï¸ InfluxDB already initialized")
                return {"success": False, "message": "InfluxDB has already been initialized"}

            auth = resData.get("auth")
            org = resData.get("org")

            if not auth or not org:
                logging.error(f"âŒ Unexpected response: {resData}")
                return {"success": False, "message": f"InfluxDB setup failed: {resData}"}

            token = auth.get("token")
            org_id = org.get("id")

            cipher = aesState.encrypt(token)
            influxdata = {
                "token": cipher,
                "org": org.get("name"),
                "org_id": org_id,
                "retention": data.get("retentionPeriodSeconds")
            }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(influxdata, f, indent=4)

        # init_influx()  # âœ… ì´ˆê¸°í™” ìˆ˜í–‰ (json ìƒì„± + client ì „ì—­ ë“±ë¡)
        if influx_state.client is None:
            return {"result": False}

        if influx_state.error:
            return {"success": False, "message": influx_state.error}
        set_cli = init_influxcli()
        sysService('restart', 'InfluxDB')
        background_tasks.add_task(complete_influx_setup)

        if set_cli['status']:
            return {"success": True, "message": "InfluxDB initialized successfully"}
        else:
            return {"success": True, "message": "InfluxDB initialized but check Influx CLI environment variables"}
    except Exception as e:
        logging.error(f"âŒ Influxdb Init Error: {e}")
        influx_state._client = None
        influx_state._error = f"Exception during init: {str(e)}"
        return {"success": False, "message": str(e)}


@router.get("/initInfluxCLI")
def init_influxcli():
    try:
        config = aesState.getInflux()
        token = aesState.decrypt(config["cipher"])

        # í† í° ê²€ì¦
        if not token or token == "":
            return {
                "status": False,
                "message": "No exist Influxdb Token"
            }

        # ë” ì•ˆì „í•œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        import shlex
        token_escaped = shlex.quote(token)
        org_escaped = shlex.quote(config['org'])

        # íŒŒì¼ ìƒì„±, ê¶Œí•œ ì„¤ì •, source ì ìš©ì„ í•œ ë²ˆì—
        full_command = f"""
cat > /etc/profile.d/influx.sh << 'EOF'
export INFLUX_TOKEN={token_escaped}
export INFLUX_HOST="http://localhost:8086"
export INFLUX_ORG={org_escaped}
export INFLUX_BUCKET="nteks"
EOF
chmod +x /etc/profile.d/influx.sh
source /etc/profile.d/influx.sh
"""

        result = subprocess.run(
            ['sudo', 'bash', '-c', full_command],
            check=True,
            capture_output=True,
            text=True
        )

        # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        os.environ.update({
            'INFLUX_TOKEN': token,
            'INFLUX_HOST': "http://localhost:8086",
            'INFLUX_ORG': config['org'],
            'INFLUX_BUCKET': "nteks"
        })

        return {
            "status": True,
            "message": "InfluxDB CLI environment initiated.",
            "file": "/etc/profile.d/influx.sh"
        }

    except subprocess.CalledProcessError as e:
        return {
            "status": False,
            "message": f"Command failed: {e.stderr if e.stderr else str(e)}"
        }
    except Exception as e:
        return {
            "status": False,
            "message": f"Error: {str(e)}"
        }


async def complete_influx_setup():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ InfluxDB ì¬ì‹œì‘ ëŒ€ê¸° í›„ ë²„í‚· ìƒì„± ë° ì„œë¹„ìŠ¤ ì¬ì‹œì‘"""
    try:
        # redis_state.client.select(0)
        sysMode = redis_state.client.hget("System", "mode")
        redis_state.client.hset("influx_init", "status", "WAITING")

        # InfluxDB ì¬ì‹œì‘ ì™„ë£Œ ëŒ€ê¸°
        await asyncio.sleep(3)
        influx_ready = False

        for i in range(10):
            try:
                async with httpx.AsyncClient(timeout=5) as client:
                    health = await client.get(f"http://127.0.0.1:8086/health")
                    if health.status_code == 200:
                        influx_ready = True
                        logging.debug("âœ… InfluxDB is ready")
                        break
            except:
                pass
            await asyncio.sleep(1)

        if not influx_ready:
            redis_state.client.hset("influx_init", "status", "FAIL")
            return

        # ë²„í‚· ìƒì„±
        bucket_result = await create_influx_bucket("ntek", 365)

        if not bucket_result["success"]:
            redis_state.client.hset("influx_init", "status", "P.FAIL")
            logging.warning(f"âš ï¸ Bucket creation failed: {bucket_result['message']}")

        # ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • (ë²„í‚· + Task) ì¶”ê°€
        downsampling_result = await setup_downsampling()
        if not downsampling_result["success"]:
            logging.warning(f"âš ï¸ Downsampling setup had issues: {downsampling_result['message']}")
        else:
            logging.info("âœ… Downsampling buckets and tasks configured")

        bucket_result2 = await create_influx_bucket("ntek30", 30)

        if not bucket_result2["success"]:
            logging.warning(f"âš ï¸ Bucket creation failed: {bucket_result2['message']}")
        # ë‹¤ë¥¸ ì„œë¹„ìŠ¤ ì¬ì‹œì‘
        if sysMode != 'device0':
            sysService('restart', 'SmartSystems')
            sysService('restart', 'SmartAPI')

        sysService('restart', 'Core')

        redis_state.client.hset("influx_init", "status", "COMPLETE")
        logging.info("âœ… InfluxDB initialization completed")

    except Exception as e:
        redis_state.client.hset("influx_init", "status", "FAIL")
        logging.error(f"âŒ Background setup error: {e}")


async def create_influx_bucket(bucket_name:str, retention:int):
    try:
        config = aesState.getInflux()
        token = aesState.decrypt(config["cipher"])
        # bucket_name = "ntek"
        retention_seconds = retention * 24 * 60 * 60
        bucket_data = {
            "orgID": config['org_id'],
            "name": bucket_name,
            "retentionRules": [
                {
                    "type": "expire",
                    "everySeconds": retention_seconds  # 2ë…„
                }
            ]
        }

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(
                f"http://127.0.0.1:8086/api/v2/buckets",
                headers={"Authorization": f"Token {token}"},
                json=bucket_data
            )

            if response.status_code == 201:
                retention_info = f"{retention_seconds // (24 * 60 * 60)} days" if retention_seconds > 0 else "infinite"
                logging.info(f"âœ… Bucket '{bucket_name}' created (retention: {retention_info})")
                return {"success": True, "message": f"Bucket '{bucket_name}' created successfully"}
            elif response.status_code == 422:  # âœ… ì´ ë¶€ë¶„ ì¶”ê°€ í•„ìš”
                logging.info(f"â„¹ï¸ Bucket '{bucket_name}' already exists")
                return {"success": True, "message": f"Bucket already exists"}
            else:
                error_msg = response.json().get("message", response.text)
                logging.error(f"âŒ Bucket '{bucket_name}' creation failed: {error_msg}")
                return {"success": False, "message": error_msg}

    except Exception as e:
        logging.error(f"âŒ Bucket creation error: {e}")
        return {"success": False, "message": str(e)}


# async def create_downsampling_buckets():
#     """ë‹¤ìš´ìƒ˜í”Œë§ìš© ë²„í‚· ìƒì„± (ntek_1h, ntek_1d)"""
#     try:
#         config = aesState.getInflux()
#         token = aesState.decrypt(config["cipher"])
#
#         buckets = [
#             {
#                 "name": "ntek_1h",
#                 "retention_seconds": 90 * 24 * 60 * 60,  # 90ì¼
#                 "description": "1ì‹œê°„ í‰ê·  ë°ì´í„°"
#             },
#             {
#                 "name": "ntek_1d",
#                 "retention_seconds": 730 * 24 * 60 * 60,  # 2ë…„
#                 "description": "1ì¼ í‰ê· /í•©ê³„ ë°ì´í„°"
#             }
#         ]
#
#         results = []
#
#         async with httpx.AsyncClient(timeout=setting_timeout) as client:
#             for bucket_info in buckets:
#                 bucket_data = {
#                     "orgID": config['org_id'],
#                     "name": bucket_info["name"],
#                     "retentionRules": []
#                 }
#
#                 # retention ì„¤ì • (0ì´ë©´ ë¬´ì œí•œ)
#                 if bucket_info["retention_seconds"] > 0:
#                     bucket_data["retentionRules"] = [
#                         {
#                             "type": "expire",
#                             "everySeconds": bucket_info["retention_seconds"]
#                         }
#                     ]
#
#                 response = await client.post(
#                     f"http://127.0.0.1:8086/api/v2/buckets",
#                     headers={"Authorization": f"Token {token}"},
#                     json=bucket_data
#                 )
#
#                 if response.status_code == 201:
#                     retention_info = f"{bucket_info['retention_seconds'] // (24 * 60 * 60)} days" if bucket_info[
#                                                                                                          'retention_seconds'] > 0 else "infinite"
#                     logging.info(f"âœ… Bucket '{bucket_info['name']}' created (retention: {retention_info})")
#                     results.append({"bucket": bucket_info["name"], "success": True})
#                 elif response.status_code == 422:
#                     # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë²„í‚·
#                     logging.info(f"â„¹ï¸ Bucket '{bucket_info['name']}' already exists")
#                     results.append({"bucket": bucket_info["name"], "success": True, "existed": True})
#                 else:
#                     error_msg = response.json().get("message", response.text)
#                     logging.error(f"âŒ Bucket '{bucket_info['name']}' creation failed: {error_msg}")
#                     results.append({"bucket": bucket_info["name"], "success": False, "error": error_msg})
#
#         success_count = sum(1 for r in results if r["success"])
#         return {
#             "success": success_count > 0,
#             "message": f"Created/verified {success_count}/{len(buckets)} buckets",
#             "results": results
#         }
#
#     except Exception as e:
#         logging.error(f"âŒ Downsampling buckets creation error: {e}")
#         return {"success": False, "message": str(e)}
#
async def create_downsampling_buckets():
    """ë‹¤ìš´ìƒ˜í”Œë§ìš© ë²„í‚· ìƒì„± (ntek_1h, ntek_1d, ntek30)"""
    try:
        results = []
        results.append(await create_influx_bucket("ntek_1h", 90))
        results.append(await create_influx_bucket("ntek_1d", 730))
        results.append(await create_influx_bucket("ntek30", 30))  # âœ… ì¶”ê°€

        success_count = sum(1 for r in results if r["success"])
        return {
            "success": success_count > 0,
            "message": f"Created/verified {success_count}/3 buckets",
            "results": results
        }

    except Exception as e:
        logging.error(f"âŒ Downsampling buckets creation error: {e}")
        return {"success": False, "message": str(e)}


async def create_downsampling_tasks():
    """ë‹¤ìš´ìƒ˜í”Œë§ Task ìƒì„±"""
    try:
        config = aesState.getInflux()
        token = aesState.decrypt(config["cipher"])
        org_name = "ntek"  # ì¡°ì§ ì´ë¦„

        tasks = [
            # Task 1: trend 5ë¶„ â†’ 1ì‹œê°„ í‰ê· 
            {
                "name": "downsample_trend_to_1h",
                "flux": f'''
option task = {{name: "downsample_trend_to_1h", every: 1h, offset: 5m}}

from(bucket: "ntek")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "trend")
  |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
  |> to(bucket: "ntek_1h", org: "{org_name}")
''',
                "every": "1h",
                "description": "Downsample trend data to 1h average"
            },

            # Task 2: trend 1ì‹œê°„ â†’ 1ì¼ í‰ê· 
            {
                "name": "downsample_trend_to_1d",
                "flux": f'''
option task = {{name: "downsample_trend_to_1d", cron: "10 0 * * *"}}

from(bucket: "ntek_1h")
  |> range(start: -1d)
  |> filter(fn: (r) => r["_measurement"] == "trend")
  |> aggregateWindow(every: 1d, fn: mean, createEmpty: false)
  |> to(bucket: "ntek_1d", org: "{org_name}")
''',
                "cron": "10 0 * * *",
                "description": "Downsample trend data to 1d average"
            },

            # Task 3: energy_consumption 1ì‹œê°„ â†’ 1ì¼ í•©ê³„
            {
                "name": "downsample_energy_consumption_to_1d",
                "flux": f'''
option task = {{name: "downsample_energy_consumption_to_1d", cron: "15 0 * * *"}}

from(bucket: "ntek")
  |> range(start: -1d)
  |> filter(fn: (r) => r["_measurement"] == "energy_consumption")
  |> aggregateWindow(every: 1d, fn: sum, createEmpty: false)
  |> to(bucket: "ntek_1d", org: "{org_name}")
''',
                "cron": "15 0 * * *",
                "description": "Downsample energy_consumption to 1d sum"
            },

            # Task 4: energy_cumulative 1ì‹œê°„ â†’ 1ì¼ ë§ˆì§€ë§‰ ê°’
            {
                "name": "downsample_energy_cumulative_to_1d",
                "flux": f'''
option task = {{name: "downsample_energy_cumulative_to_1d", cron: "20 0 * * *"}}

from(bucket: "ntek")
  |> range(start: -1d)
  |> filter(fn: (r) => r["_measurement"] == "energy_cumulative")
  |> aggregateWindow(every: 1d, fn: last, createEmpty: false)
  |> to(bucket: "ntek_1d", org: "{org_name}")
''',
                "cron": "20 0 * * *",
                "description": "Downsample energy_cumulative to 1d last value"
            }
        ]

        results = []

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            for task_info in tasks:
                task_data = {
                    "orgID": config['org_id'],
                    "org": org_name,
                    "name": task_info["name"],
                    "description": task_info["description"],
                    "status": "active",
                    "flux": task_info["flux"]
                }

                response = await client.post(
                    f"http://127.0.0.1:8086/api/v2/tasks",
                    headers={"Authorization": f"Token {token}"},
                    json=task_data
                )

                if response.status_code == 201:
                    task_id = response.json().get("id")
                    logging.info(f"âœ… Task '{task_info['name']}' created (ID: {task_id})")
                    results.append({"task": task_info["name"], "success": True, "id": task_id})
                elif response.status_code == 422:
                    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” Task
                    logging.info(f"â„¹ï¸ Task '{task_info['name']}' already exists")
                    results.append({"task": task_info["name"], "success": True, "existed": True})
                else:
                    error_msg = response.json().get("message", response.text)
                    logging.error(f"âŒ Task '{task_info['name']}' creation failed: {error_msg}")
                    results.append({"task": task_info["name"], "success": False, "error": error_msg})

        success_count = sum(1 for r in results if r["success"])
        return {
            "success": success_count > 0,
            "message": f"Created/verified {success_count}/{len(tasks)} tasks",
            "results": results
        }

    except Exception as e:
        logging.error(f"âŒ Downsampling tasks creation error: {e}")
        return {"success": False, "message": str(e)}


async def setup_downsampling():
    """ë‹¤ìš´ìƒ˜í”Œë§ ì „ì²´ ì„¤ì • (ë²„í‚· + Task)"""
    try:
        logging.info("ğŸ”§ Starting downsampling setup...")

        # 1. ë²„í‚· ìƒì„±
        bucket_result = await create_downsampling_buckets()
        if not bucket_result["success"]:
            logging.warning(f"âš ï¸ Bucket creation had issues: {bucket_result['message']}")

        # 2. Task ìƒì„±
        task_result = await create_downsampling_tasks()
        if not task_result["success"]:
            logging.warning(f"âš ï¸ Task creation had issues: {task_result['message']}")

        # 3. ê²°ê³¼ ìš”ì•½
        overall_success = bucket_result["success"] and task_result["success"]

        if overall_success:
            # redis_state.client.select(0)
            redis_state.client.hset("influx_init", "status", "COMPLETE")
            logging.info("âœ… Downsampling setup completed successfully")
            return {
                "success": True,
                "message": "Downsampling buckets and tasks created",
                "buckets": bucket_result["results"],
                "tasks": task_result["results"]
            }
        else:
            return {
                "success": False,
                "message": "Downsampling setup had issues",
                "buckets": bucket_result.get("results", []),
                "tasks": task_result.get("results", [])
            }

    except Exception as e:
        logging.error(f"âŒ Downsampling setup error: {e}")
        return {"success": False, "message": str(e)}


@router.get('/setup-downsampling')
async def setup_downsampling_endpoint():
    """
    ë‹¤ìš´ìƒ˜í”Œë§ ë²„í‚·ê³¼ Taskë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ì—…ë°ì´íŠ¸ í›„ 1íšŒ ì‹¤í–‰ìš©)

    ìƒì„± í•­ëª©:
    - ë²„í‚·: ntek_1h (90ì¼), ntek_1d (2ë…„)
    - Task: trend 5ë¶„â†’1ì‹œê°„â†’1ì¼, energy ì¼ê°„ ì§‘ê³„
    """
    try:
        logging.info("ğŸ”§ ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • ì‹œì‘...")

        result = await setup_downsampling()

        if result["success"]:
            logging.info("âœ… ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • ì™„ë£Œ")
            return {
                "result": True,
                "message": "ë‹¤ìš´ìƒ˜í”Œë§ ë²„í‚· ë° Taskê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "buckets": result.get("buckets", []),
                "tasks": result.get("tasks", [])
            }
        else:
            logging.warning(f"âš ï¸ ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • ì¤‘ ì¼ë¶€ ì‹¤íŒ¨: {result['message']}")
            return {
                "result": False,
                "message": result["message"],
                "buckets": result.get("buckets", []),
                "tasks": result.get("tasks", [])
            }

    except Exception as e:
        logging.error(f"âŒ ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return{
            "result": False,
            "message":f"ë‹¤ìš´ìƒ˜í”Œë§ ì„¤ì • ì‹¤íŒ¨: {str(e)}"
        }

@router.get('/check-downsampling')
async def check_downsampling_status():
    """
    ë‹¤ìš´ìƒ˜í”Œë§ ë²„í‚·ê³¼ Taskì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        # 1. org_id í™•ì¸ ë° ê°€ì ¸ì˜¤ê¸°
        ret = check_org_id_exists()
        print(f"check_org_id_exists: {ret}")

        if not ret["result"]:
            # org_idê°€ ì—†ìœ¼ë©´ InfluxDBì—ì„œ ì¡°íšŒí•´ì„œ ì €ì¥
            org_id = await get_org_id_from_influxdb()
            if not org_id:
                return {
                    "result": False,
                    "message": "org_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }

        # 2. config ê°€ì ¸ì˜¤ê¸°
        config = aesState.getInflux()

        if not config["result"]:
            return {
                "result": False,
                "message": "InfluxDB ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            }

        # 3. org_id í™•ì¸ (getInflux ê²°ê³¼ì— ì—†ì„ ìˆ˜ë„ ìˆìŒ)
        if "org_id" not in config or not config["org_id"]:
            # íŒŒì¼ì—ì„œ ë‹¤ì‹œ í™•ì¸
            ret = check_org_id_exists()
            if ret["result"] and ret["org_id"]:
                config["org_id"] = ret["org_id"]
            else:
                return {
                    "result": False,
                    "message": "org_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }

        token = aesState.decrypt(config["cipher"])

        bucket_names = ["ntek_1h", "ntek_1d", "ntek30"]
        task_names = [
            "downsample_trend_to_1h",
            "downsample_trend_to_1d",
            "downsample_energy_consumption_to_1d",
            "downsample_energy_cumulative_to_1d"
        ]

        bucket_status = []
        task_status = []

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            # ë²„í‚· ìƒíƒœ í™•ì¸
            try:
                buckets_response = await client.get(
                    f"http://127.0.0.1:8086/api/v2/buckets",
                    headers={"Authorization": f"Token {token}"},
                    params={"orgID": config['org_id']}
                )

                if buckets_response.status_code == 200:
                    all_buckets = buckets_response.json().get("buckets", [])

                    for bucket_name in bucket_names:
                        bucket = next((b for b in all_buckets if b["name"] == bucket_name), None)

                        if bucket:
                            retention = bucket.get("retentionRules", [])
                            retention_seconds = retention[0]["everySeconds"] if retention else 0
                            retention_days = retention_seconds // (
                                        24 * 60 * 60) if retention_seconds > 0 else "infinite"

                            bucket_status.append({
                                "name": bucket_name,
                                "exists": True,
                                "id": bucket["id"],
                                "retention_days": retention_days,
                                "created_at": bucket.get("createdAt")
                            })
                        else:
                            bucket_status.append({
                                "name": bucket_name,
                                "exists": False
                            })
                else:
                    logging.error(f"âŒ ë²„í‚· ì¡°íšŒ ì‹¤íŒ¨: {buckets_response.status_code}")

            except Exception as e:
                logging.error(f"âŒ ë²„í‚· ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                for bucket_name in bucket_names:
                    bucket_status.append({
                        "name": bucket_name,
                        "exists": False,
                        "error": str(e)
                    })

            # Task ìƒíƒœ í™•ì¸
            try:
                tasks_response = await client.get(
                    f"http://127.0.0.1:8086/api/v2/tasks",
                    headers={"Authorization": f"Token {token}"},
                    params={"orgID": config['org_id']}
                )

                if tasks_response.status_code == 200:
                    all_tasks = tasks_response.json().get("tasks", [])

                    for task_name in task_names:
                        task = next((t for t in all_tasks if t["name"] == task_name), None)

                        if task:
                            task_status.append({
                                "name": task_name,
                                "exists": True,
                                "id": task["id"],
                                "status": task.get("status"),
                                "created_at": task.get("createdAt"),
                                "last_run_status": task.get("lastRunStatus"),
                                "last_run_error": task.get("lastRunError")
                            })
                        else:
                            task_status.append({
                                "name": task_name,
                                "exists": False
                            })
                else:
                    logging.error(f"âŒ Task ì¡°íšŒ ì‹¤íŒ¨: {tasks_response.status_code}")

            except Exception as e:
                logging.error(f"âŒ Task ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                for task_name in task_names:
                    task_status.append({
                        "name": task_name,
                        "exists": False,
                        "error": str(e)
                    })

        # ì „ì²´ ìƒíƒœ íŒë‹¨
        all_buckets_exist = all(b["exists"] for b in bucket_status)
        all_tasks_exist = all(t["exists"] for t in task_status)

        return {
            "result": True,
            "all_configured": all_buckets_exist and all_tasks_exist,
            "buckets": {
                "all_exist": all_buckets_exist,
                "details": bucket_status
            },
            "tasks": {
                "all_exist": all_tasks_exist,
                "details": task_status
            },
            "summary": {
                "buckets_count": f"{sum(1 for b in bucket_status if b['exists'])}/{len(bucket_names)}",
                "tasks_count": f"{sum(1 for t in task_status if t['exists'])}/{len(task_names)}"
            }
        }

    except Exception as e:
        logging.error(f"âŒ ë‹¤ìš´ìƒ˜í”Œë§ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {
            "result": False,
            "message": f"ë‹¤ìš´ìƒ˜í”Œë§ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}"
        }


def check_org_id_exists():
    """
    influx.jsonì— org_idê°€ ìˆëŠ”ì§€ í™•ì¸

    Returns:
        bool: org_idê°€ ìˆìœ¼ë©´ True, ì—†ìœ¼ë©´ False
    """
    try:
        file_path = os.path.join(SETTING_FOLDER, 'influx.json')

        if not os.path.exists(file_path):
            return {"result": False}

        with open(file_path, "r", encoding="utf-8") as f:
            influx_config = json.load(f)

        if "org_id" in influx_config and influx_config["org_id"]:
            return {"result": True, "org_id": influx_config["org_id"]}
        else:
            return {"result": False, "org_id": None}

    except Exception as e:
        logging.error(f"âŒ Error checking org_id: {e}")
        return {"result": False}


async def get_org_id_from_influxdb(org_name: str = "ntek") -> str:
    """
    InfluxDBì—ì„œ organization IDë¥¼ ì¡°íšŒí•˜ê³  influx.jsonì— ì €ì¥

    Args:
        org_name: ì¡°ì§ ì´ë¦„ (ê¸°ë³¸ê°’: "ntek")

    Returns:
        str: org_id ë˜ëŠ” None
    """
    try:
        config = aesState.getInflux()
        token = aesState.decrypt(config["cipher"])

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(
                "http://127.0.0.1:8086/api/v2/orgs",
                headers={"Authorization": f"Token {token}"}
            )

            if response.status_code == 200:
                orgs = response.json().get("orgs", [])
                target_org = next((org for org in orgs if org["name"] == org_name), None)

                if target_org:
                    org_id = target_org["id"]
                    logging.info(f"âœ… Found org_id: {org_id}")

                    # influx.jsonì— org_id ì €ì¥
                    file_path = os.path.join(SETTING_FOLDER, 'influx.json')
                    with open(file_path, "r", encoding="utf-8") as f:
                        influx_config = json.load(f)

                    influx_config["org_id"] = org_id

                    with open(file_path, "w", encoding="utf-8") as f:
                        json.dump(influx_config, f, indent=4)

                    logging.info(f"âœ… org_id saved to influx.json")

                    return org_id
                else:
                    logging.warning(f"âš ï¸ Organization '{org_name}' not found")
                    return None
            else:
                logging.error(f"âŒ API error: {response.status_code}")
                return None

    except Exception as e:
        logging.error(f"âŒ Error getting org_id: {e}")
        return None


@router.get('/initDB/status')
async def get_init_status():
    # redis_state.client.select(0)
    status = redis_state.client.hget("influx_init", "status") or "IDLE"
    return {"status": status}


@router.get("/backup/download/{backup_type}")
async def download_backup(backup_type: str):
    try:
        LOG_PATH = '/usr/local/sv500/logs'
        BACKUP_DIR = '/usr/local/sv500/backup/influxdb'  # âœ…

        # ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„± ì‹œë„ (ê¶Œí•œ ìˆì„ ë•Œë§Œ ê°€ëŠ¥)
        if not os.path.exists(BACKUP_DIR):
            try:
                os.makedirs(BACKUP_DIR, exist_ok=True)
            except PermissionError:
                return {"success": False, "message": "Backup directory not accessible. Please run installation script."}

        temp_dir = tempfile.mkdtemp(dir=BACKUP_DIR)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        #        background_tasks.add_task(shutil.rmtree, temp_dir)

        if backup_type in ["all", "other"]:
            # InfluxDB + logs í†µí•© ë°±ì—…
            return await _backup_all(temp_dir, timestamp, LOG_PATH)

        elif backup_type == "dbbackup":
            # InfluxDBë§Œ ë°±ì—…
            return await _backup_influxdb(temp_dir, timestamp)

        elif backup_type == "log":
            # logs í´ë”ë§Œ ë°±ì—…
            return await _backup_logs(temp_dir, timestamp, LOG_PATH)

        else:
            shutil.rmtree(temp_dir)
            return {"success": False, "message": "Invalid backup_type. Use: all, dbbackup, or logs"}

    except Exception as e:
        logging.error(f"âŒ Backup error: {e}")
        return {"success": False, "message": str(e)}


async def _backup_all(temp_dir: str, timestamp: str, log_dir: str):
    """InfluxDB + logs í†µí•© ë°±ì—…"""
    try:
        config = aesState.getInflux()
        if not config["result"]:
            return {"success": False, "message": "InfluxDB not initialized"}

        token = aesState.decrypt(config["cipher"])
        org = config["org"]

        backup_name = f"backup_all_{timestamp}"
        backup_path = os.path.join(temp_dir, backup_name)
        os.makedirs(backup_path, exist_ok=True)

        # âœ… ì„ì‹œ InfluxDB ë°±ì—… (ë£¨íŠ¸ ë ˆë²¨ì—)
        temp_influx_backup = os.path.join(temp_dir, f"temp_influx_{timestamp}")

        backup_command = f"""
export INFLUX_TOKEN='{token}'
export INFLUX_HOST='http://localhost:8086'
export INFLUX_ORG='{org}'
influx backup {temp_influx_backup} --bucket ntek
"""

        result = subprocess.run(
            ['bash', '-c', backup_command],
            check=True,
            capture_output=True,
            text=True,
            timeout=300
        )

        logging.info(f"ğŸ“‹ Backup stdout: {result.stdout}")
        logging.info(f"ğŸ“‹ Backup stderr: {result.stderr}")

        logging.info(f"âœ… InfluxDB backup completed")

        # âœ… ë°±ì—…ì„ ìµœì¢… ìœ„ì¹˜ë¡œ ì´ë™
        influx_backup_path = os.path.join(backup_path, "influxdb")
        shutil.move(temp_influx_backup, influx_backup_path)
        logging.info(f"âœ… InfluxDB backup moved to final location")

        # 2. logs í´ë” ë³µì‚¬
        if os.path.exists(log_dir):
            logs_backup_path = os.path.join(backup_path, "logs")
            shutil.copytree(log_dir, logs_backup_path)
            logging.info(f"âœ… Logs copied")

        # 3. í†µí•© ì••ì¶•
        #        tar_file = f"{backup_path}.tar.gz"
        parent_dir = os.path.dirname(temp_dir)
        tar_file = os.path.join(parent_dir, f"{backup_name}.tar.gz")

        result = subprocess.run(
            ['tar', '--ignore-failed-read', '-czf', tar_file, '-C', temp_dir, backup_name],
            capture_output=True,
            text=True,
            timeout=300
        )

        # âœ… exit code 0 ë˜ëŠ” 1 í—ˆìš©
        if result.returncode > 1:
            raise subprocess.CalledProcessError(result.returncode, ['tar'], result.stdout, result.stderr)

        if not os.path.exists(tar_file):
            raise Exception("Backup file not created")

        logging.info(f"âœ… All backup created: {backup_name}.tar.gz")

        def cleanup():
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                if os.path.exists(tar_file):
                    os.remove(tar_file)
            except Exception as e:
                logging.error(f"Cleanup error: {e}")

        return FileResponse(
            path=tar_file,
            filename=f"{backup_name}.tar.gz",
            media_type='application/gzip',
            background=BackgroundTask(cleanup)
        )

    except subprocess.TimeoutExpired:
        logging.error("âŒ Backup timeout")
        return {"success": False, "message": "Backup timeout"}
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        logging.error(f"âŒ Backup failed: {error_msg}")
        return {"success": False, "message": f"Backup failed: {error_msg}"}


async def _backup_influxdb(temp_dir: str, timestamp: str):
    """InfluxDBë§Œ ë°±ì—…"""
    try:
        config = aesState.getInflux()
        if not config["result"]:
            return {"success": False, "message": "InfluxDB not initialized"}

        token = aesState.decrypt(config["cipher"])
        org = config["org"]

        backup_name = f"backup_influxdb_{timestamp}"
        backup_path = os.path.join(temp_dir, backup_name)

        backup_command = f"""
set -e
export INFLUX_TOKEN='{token}'
export INFLUX_HOST='http://localhost:8086'
export INFLUX_ORG='{org}'
influx backup {backup_path} --bucket ntek
"""

        result = subprocess.run(
            ['bash', '-c', backup_command],
            check=True,
            capture_output=True,
            text=True,
            timeout=300
        )

        # âœ… tar íŒŒì¼ì„ ë¶€ëª¨ ë””ë ‰í† ë¦¬ì— ìƒì„±
        parent_dir = os.path.dirname(temp_dir)
        tar_file = os.path.join(parent_dir, f"{backup_name}.tar.gz")

        subprocess.run(
            ['tar', '-czf', tar_file, '-C', temp_dir, backup_name],
            check=True,
            timeout=300
        )

        if not os.path.exists(tar_file):
            raise Exception("Backup file not created")

        logging.info(f"âœ… InfluxDB backup created: {backup_name}.tar.gz")

        # âœ… ì •ë¦¬ í•¨ìˆ˜
        def cleanup():
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                if os.path.exists(tar_file):
                    os.remove(tar_file)
            except Exception as e:
                logging.error(f"Cleanup error: {e}")

        return FileResponse(
            path=tar_file,
            filename=f"{backup_name}.tar.gz",
            media_type='application/gzip',
            background=BackgroundTask(cleanup)
        )

    except subprocess.TimeoutExpired:
        return {"success": False, "message": "Backup timeout"}
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        logging.error(f"âŒ Backup failed: {error_msg}")
        return {"success": False, "message": f"Backup failed: {error_msg}"}


async def _backup_logs(temp_dir: str, timestamp: str, log_dir: str):
    """logs í´ë”ë§Œ ë°±ì—…"""
    try:
        if not os.path.exists(log_dir):
            return {"success": False, "message": f"Logs directory not found: {log_dir}"}

        backup_name = f"backup_logs_{timestamp}"

        # âœ… tar íŒŒì¼ì„ ë¶€ëª¨ ë””ë ‰í† ë¦¬ì— ìƒì„±
        parent_dir = os.path.dirname(temp_dir)
        tar_file = os.path.join(parent_dir, f"{backup_name}.tar.gz")

        # logs í´ë” ì••ì¶•
        result = subprocess.run(
            ['tar', '--ignore-failed-read', '-czf', tar_file, '-C', os.path.dirname(log_dir),
             os.path.basename(log_dir)],
            capture_output=True,  # âœ… ì¶”ê°€
            text=True,  # âœ… ì¶”ê°€
            timeout=300
        )

        logging.info(f"ğŸ“‹ tar stderr: {result.stderr}")

        # âœ… exit code 0 ë˜ëŠ” 1 ëª¨ë‘ í—ˆìš© (1ì€ ê²½ê³ )
        if result.returncode > 1:
            raise subprocess.CalledProcessError(
                result.returncode,
                ['tar'],
                result.stdout,
                result.stderr
            )

        if not os.path.exists(tar_file):
            raise Exception("Backup file not created")

        logging.info(f"âœ… Logs backup created: {backup_name}.tar.gz")

        # âœ… ì •ë¦¬ í•¨ìˆ˜
        def cleanup():
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                if os.path.exists(tar_file):
                    os.remove(tar_file)
            except Exception as e:
                logging.error(f"Cleanup error: {e}")

        return FileResponse(
            path=tar_file,
            filename=f"{backup_name}.tar.gz",
            media_type='application/gzip',
            background=BackgroundTask(cleanup)
        )

    except subprocess.TimeoutExpired:
        return {"success": False, "message": "Backup timeout"}
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        logging.error(f"âŒ Backup failed: {error_msg}")
        return {"success": False, "message": f"Backup failed: {error_msg}"}

def parse_settings(setting):
    """ì„¤ì •ì„ íŒŒì‹±í•˜ì—¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    # ê¸°ë³¸ê°’ ì„¤ì •
    result = {
        "result": "1",
        "mode": setting.get("mode", ""),
        "lang": setting.get("lang", ""),
        "location": "",
        "Diag_main": False,
        "Diag_sub": False,
        "enable_main": False,
        "enable_sub": False,
        "pq_main": False,
        "pq_sub": False,
        "assetType_main": "",
        "assetName_main": "",
        "assetType_sub": "",
        "assetName_sub": "",
        "assetNickname_main": "",
        "assetNickname_sub": "",
        "assetdriveType_main":"",
        "assetdriveType_sub": "",
        "main_kva": -1,
        "sub_kva": -1,
        "pf_sign": -1,
        "va_type": -1,
        "unbalance":-1
    }

    # channel ê²€ì¦
    if "channel" not in setting:
        result["result"] = "0"
        return result

    # device ëª¨ë“œì¸ ê²½ìš°ë§Œ ìƒì„¸ ì •ë³´ íŒŒì‹±
    if 'device' in result["mode"]:
        # General ì •ë³´ íŒŒì‹±
        general_data = setting.get("General", {})
        use_function = general_data.get("useFuction", {})  # ì˜¤íƒ€ ìˆ˜ì • í•„ìš”
        dev_info = general_data.get("deviceInfo", {})
        result["pf_sign"] = general_data.get("pf_sign", 0)
        result["va_type"] = general_data.get("va_type", 0)
        result["unbalance"] = general_data.get("unbalance", 0)
        result["location"] = dev_info.get("location", "")
        result["Diag_main"] = bool(use_function.get("diagnosis_main", 0))
        result["Diag_sub"] = bool(use_function.get("diagnosis_sub", 0))

        # ì±„ë„ë³„ ì •ë³´ íŒŒì‹±
        for channel_data in setting["channel"]:
            channel_name = channel_data.get("channel", "")

            if channel_name == "Main":
                parse_channel_data(channel_data, result, "main", result["Diag_main"])
            elif channel_name == "Sub":
                parse_channel_data(channel_data, result, "sub", result["Diag_sub"])

    return result


def parse_channel_data(channel_data, result, prefix, diag_enabled):
    """ì±„ë„ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ê²°ê³¼ì— ì¶”ê°€"""
    result[f"enable_{prefix}"] = bool(channel_data.get("Enable", 0))
    result[f"pq_{prefix}"] = bool(channel_data.get("PowerQuality", 0))

    if diag_enabled:
        asset_info = channel_data.get("assetInfo", {})
        result[f"assetType_{prefix}"] = asset_info.get("type", "")
        result[f"assetName_{prefix}"] = asset_info.get("name", "")
        result[f"assetNickname_{prefix}"] = asset_info.get("nickname", "")
        result[f"assetdriveType_{prefix}"] = asset_info.get("driveType", "")

        if asset_info.get("type") == 'Transformer':
            result[f"{prefix}_kva"] = int(channel_data.get("n_kva", 0))

@router.get('/checkSettingFile') #check setup.json
def check_setupfile(request: Request):
    """
    ìš°ì„ ìˆœìœ„:
    1. setup.json íŒŒì¼ í™•ì¸ (ìµœìš°ì„ )
    2. íŒŒì¼ì´ ì—†ìœ¼ë©´ default.jsonìœ¼ë¡œ ìƒì„±
    3. Redisì— ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œí•˜ì—¬ Redisì— ì €ì¥
    """
    file_path = os.path.join(SETTING_FOLDER, 'setup.json')
    default_file_path = os.path.join(SETTING_FOLDER, 'default.json')
    deviceMac = get_mac_address()
    ser = ''
    if os_spec.os != 'Windows':
        mac_file_path = os.path.join(SETTING_FOLDER, 'serial_num_do_not_modify.txt')
        if os.path.exists(mac_file_path):
            ser = read_mac_plain(mac_file_path)

            # if ser != deviceMac:
            #     deviceMac = ser

    if redis_state.client is None:
        return {"result": "0", "error": "Redis not available"}

    try:
        # redis_state.client.select(0)

        # 1. ë¨¼ì € setup.json íŒŒì¼ í™•ì¸ ë° ìƒì„±
        if not os.path.exists(file_path):
            # setup.jsonì´ ì—†ìœ¼ë©´ default.jsonìœ¼ë¡œ ìƒì„±
            if os.path.exists(default_file_path):
                shutil.copy(default_file_path, file_path)
            else:
                return {"result": "0", "error": "No default.json found"}

        # 2. Redisì— setupì´ ìˆëŠ”ì§€ í™•ì¸
        if redis_state.client.hexists("System", "setup"):
            # Redisì— ìˆìœ¼ë©´ Redis ë°ì´í„° ì‚¬ìš©
            setting = json.loads(redis_state.client.hget("System", "setup"))
            # deviceMac = get_mac_address()
            if deviceMac != setting["General"]["deviceInfo"]["mac_address"]:
                setting["General"]["deviceInfo"]["mac_address"] = deviceMac
            if ser != '':
                setting["General"]["deviceInfo"]["serial_number"] = ser
            else:
                setting["General"]["deviceInfo"]["mac_address"] = deviceMac

        else:
            # Redisì— ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ì½ì–´ì„œ Redisì— ì €ì¥
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    setting = json.load(f)
            except json.JSONDecodeError:
                # setup.jsonì´ ì†ìƒëœ ê²½ìš° default.jsonìœ¼ë¡œ ë³µêµ¬
                shutil.copy(default_file_path, file_path)
                with open(file_path, "r", encoding="utf-8") as f:
                    setting = json.load(f)

            # Redisì— ì €ì¥
            # deviceMac = get_mac_address()
            if deviceMac != setting["General"]["deviceInfo"]["mac_address"]:
                setting["General"]["deviceInfo"]["mac_address"] = deviceMac
                # setting["General"]["deviceInfo"]["serial_number"] = deviceMac
            if ser != '':
                setting["General"]["deviceInfo"]["serial_number"] = ser
            else:
                setting["General"]["deviceInfo"]["mac_address"] = deviceMac

            redis_state.client.hset("System", "setup", json.dumps(setting))
            if "mode" in setting:
                redis_state.client.hset("System", "mode", setting["mode"])

        for idx, ch in enumerate(setting["channel"]):
            setting["channel"][idx]["ctInfo"]["inorminal"] = float(setting["channel"][idx]["ctInfo"]["inorminal"])/1000

        # 3. ì„¤ì • íŒŒì‹± ë° ë°˜í™˜
        return parse_settings(setting)

    except Exception as e:
        return {"result": "0", "error": str(e)}

def saveStartCurrent(setting):
    main_channel_data = next((ch for ch in setting["channel"] if ch.get("channel") == "Main"), None)
    if main_channel_data:
        main_c = int(main_channel_data["ctInfo"]["startingcurrent"]) / 1000
    else:
        main_c = 0
    sub_channel_data = next((ch for ch in setting["channel"] if ch.get("channel") == "Sub"), None)
    if sub_channel_data:
        sub_c = int(sub_channel_data["ctInfo"]["startingcurrent"]) / 1000
    else:
        sub_c = 0
    return {"main": main_c, "sub": sub_c}

def save_StartCurrent_DemandInterval_SamplingPeriod(setting):
    main_channel_data = next((ch for ch in setting["channel"] if ch.get("channel") == "Main"), None)
    if main_channel_data:
        main_c = int(main_channel_data["ctInfo"]["startingcurrent"]) / 1000
        if int(main_channel_data["demand"]["demand_interval"]) != 15:
            main_d = int(main_channel_data["demand"]["demand_interval"])*60
        else:
            main_d = 15*60
        main_s = int(main_channel_data["sampling"]["period"])*60
        main_data = {
            "PT_WiringMode":int(main_channel_data["ptInfo"]["wiringmode"]),
            "RatedFrequency": int(main_channel_data["ptInfo"]["linefrequency"]),
            "RatedVoltage": int(main_channel_data["ptInfo"]["vnorminal"]),
            "RatedCurrent": int(main_channel_data["ctInfo"]["inorminal"]),
            "RatedKVA": int(main_channel_data["n_kva"])
        }
    else:
        main_c = 0
        main_d = 15*60
        main_s = 0
        main_data = {}
    sub_channel_data = next((ch for ch in setting["channel"] if ch.get("channel") == "Sub"), None)
    if sub_channel_data:
        sub_c = int(sub_channel_data["ctInfo"]["startingcurrent"]) / 1000
        if int(sub_channel_data["demand"]["demand_interval"]) != 15:
            sub_d = int(sub_channel_data["demand"]["demand_interval"])*60
        else:
            sub_d = 15 * 60
        sub_s = int(sub_channel_data["sampling"]["period"])*60
        sub_data = {
            "PT_WiringMode": int(sub_channel_data["ptInfo"]["wiringmode"]),
            "RatedFrequency": int(sub_channel_data["ptInfo"]["linefrequency"]),
            "RatedVoltage": int(sub_channel_data["ptInfo"]["vnorminal"]),
            "RatedCurrent": int(sub_channel_data["ctInfo"]["inorminal"]),
            "RatedKVA": int(sub_channel_data["n_kva"])
        }
    else:
        sub_c = 0
        sub_d = 15*60
        sub_s = 0
        sub_data = {}
    return {"StartCurrent":{"main": main_c, "sub": sub_c},"Demand":{"main": main_d, "sub": sub_d},
            "Sampling":{"main": main_s, "sub": sub_s}, "Channel": {"main": main_data, "sub":sub_data}}

@router.get('/getSetting')
def get_setting():
    # redis_state.client.execute_command("SELECT", 0)
    if redis_state.client.hexists("System", "setup"):
        redisContext = redis_state.client.hget("System", "setup")
        setting = json.loads(redisContext)
    else:
        file_path = os.path.join(SETTING_FOLDER, 'setup.json')
        if not os.path.exists(file_path):
            return {"passOK": 0, "error": "setting file not found"}
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                setting = json.load(f)
        except Exception as e:
            return {"passOK": 0}

    for idx, ch in enumerate(setting["channel"]):
        setting["channel"][idx]["ctInfo"]["inorminal"] = float(
            setting["channel"][idx]["ctInfo"]["inorminal"]) / 1000

    setup_dict = {
        "mode": setting.get("mode", ""),
        "lang": setting.get("lang",""),
        "General": setting.get("General", {}),
        "main": {},
        "sub": {}
    }

    for ch in setting.get("channel", []):
        name = ch.get("channel", "")
        if name == "Main":
            setup_dict["main"] = ch
        elif name == "Sub":
            setup_dict["sub"] = ch

    return {"passOK": 1, "data":setup_dict}

@router.get('/getSettingData/{channel}')  # get setting with setup.json
def getDatafromSetting(channel):
    # redis_state.client.execute_command("SELECT", 0)
    if redis_state.client.hexists("System", "setup"):
        redisContext = redis_state.client.hget("System", "setup")
        setting = json.loads(redisContext)
    else:
        file_path = os.path.join(SETTING_FOLDER, 'setup.json')
        if not os.path.exists(file_path):
            return {"passOK": "0", "error": "setting file not found"}
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                    setting = json.load(f)
        except Exception as e:
            return {"passOK": "0"}

    for idx, ch in enumerate(setting["channel"]):
        setting["channel"][idx]["ctInfo"]["inorminal"] = float(
            setting["channel"][idx]["ctInfo"]["inorminal"]) / 1000

    if channel in setting:
        return {"passOK": "1", "data": setting[channel]}
    else:
        main_channel = [ch for ch in setting["channel"] if ch["channel"] == channel]
        if not main_channel:
            return {"passOK": "0"}
        else:
            return {"passOK": "1", "data": main_channel}


@router.get('/Reset')
def reset():
    msg = ''

    if not redis_state.client is None:
        # redis_state.client.execute_command("SELECT", 0)
        if redis_state.client.hexists("Service","setting"):
            checkflag = redis_state.client.hget("Service","setting")
            if int(checkflag) == 1:
                return {"success": False, "msg": "Modbus setting is activated"}

        setting_path = os.path.join(SETTING_FOLDER, 'setup.json')
        backup_file_path = os.path.join(SETTING_FOLDER, 'setup_backup.json')
        try:
            if os.path.exists(setting_path):
                shutil.copy(setting_path, backup_file_path)  # setup.jsonì„ setting_backup.jsonìœ¼ë¡œ ë°±ì—…
                os.remove(setting_path)
            else:
                msg = "No exist setup.json"

            if redis_state.client.hexists("System", "setup"):
                nowSetup = json.loads(redis_state.client.hget("System", "setup"))
                default_file_path = os.path.join(SETTING_FOLDER, 'default.json')

                with open(default_file_path, "r", encoding="utf-8") as f:
                    defaults = json.load(f)

                defaults["mode"] = nowSetup["mode"]
                defaults["General"]["deviceInfo"]["mac_address"] = get_mac_address()
                defaults["General"]["deviceInfo"]["serial_number"] = get_mac_address()

                with open(default_file_path, "w", encoding="utf-8") as f:
                    json.dump(defaults, f, indent=2)  # indent ì¶”ê°€ë¡œ ê°€ë…ì„± í–¥ìƒ

                redis_state.client.hdel("System", "setup")
        except Exception as e:
            print(str(e))
            return {"success": False, "msg": str(e)}
    else:
        msg += "No saved setup in Redis"
    if msg == '':
        return {"success": True, "msg": "Reset success"}
    else:
        return {"success": True, "msg": msg}


async def reset_count(request:Request):
    # redis_state.client.select(0)
    if redis_state.client.hexists("System","setup"):
        setup = json.loads(redis_state.client.hget("System","setup"))
        mainEnable = 0
        subEnable = 0
        for chInfo in setup["channel"]:
            if chInfo["channel"] == 'Main':
                mainEnable = chInfo["Enable"]
                break
        for chInfo in setup["channel"]:
            if chInfo["channel"] == 'Sub':
                subEnable = chInfo["Enable"]
                break
        if mainEnable == 1:
            allcmd0 = Command(type=0, cmd=0, item=8)  # all item clear  (add item 8 to minhyuk)
            ret0 = await push_command_left(allcmd0, request)
            if not ret0["success"]:
                return False
        if subEnable == 1:
            allcmd1 = Command(type=1, cmd=0, item=8)  # all item clear  (add item 8 to minhyuk)
            ret1 = await push_command_left(allcmd1, request)
            if not ret1["success"]:
                return False

        return True
    else:
        return False


async def reset_system(request:Request):
    ret = sysService("stop", "Core")
    retflag = True
    if ret["success"]:
        try:
            start = "1970-01-01T00:00:00Z"
            stop = datetime.utcnow().isoformat() + "Z"

            # ntek ë²„í‚·ì˜ measurement ëª©ë¡ ì¡°íšŒ í›„ ì‚­ì œ
            query = '''
            import "influxdata/influxdb/schema"
            schema.measurements(bucket: "ntek")
            '''

            try:
                tables = influx_state.query_api.query(query, org='ntek')
                measurements = []
                for table in tables:
                    for record in table.records:
                        meas_name = record.values.get("_value")
                        if meas_name:
                            measurements.append(meas_name)

                # ê° measurement ê°œë³„ ì‚­ì œ
                for measurement in measurements:
                    try:
                        influx_state.delete_api.delete(
                            start=start,
                            stop=stop,
                            predicate=f'_measurement="{measurement}"',
                            bucket='ntek',
                            org='ntek'
                        )
                        logging.info(f"âœ… Deleted measurement: {measurement} from ntek")
                    except Exception as e:
                        retflag = False
                        logging.warning(f"âš ï¸ Failed to delete {measurement}: {e}")
                        break

            except Exception as e:
                logging.warning(f"âš ï¸ No measurements found in ntek or query failed: {e}")
                retflag = True  # ë°ì´í„°ê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬

        except Exception as e:
            retflag = False
            logging.error(f"âŒ Failed to delete InfluxDB ntek bucket: {e}")
            return {"success": False, "msg": f"Failed deleting Influxdb: {str(e)}"}
    else:
        retflag = False
        return {"success": False, "msg": "Failed stopping core service"}

    # SmartSystem ë²„í‚·ë“¤ë„ ë™ì¼í•˜ê²Œ measurement ì‚­ì œ
    if service_exists("smartsystemsservice.service"):
        result = await reinstall_smartsystem()
        retflag = result["success"]

    if retflag:
        res = await reset_count(request)
        if not res:
            return {"success": False, "msg": "Failed clearing system count"}
        return {"success": True}
    else:
        return {"success": False, "msg": "System reset incomplete"}


async def reinstall_smartsystem():
    """SmartSystem ì¬ì„¤ì¹˜ë¡œ ì™„ì „ ì´ˆê¸°í™”"""
    try:
        # ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
        install_script = "/usr/local/sv500/iss/install.sh"  # ì˜ˆì‹œ

        if not os.path.exists(install_script):
            # ë˜ëŠ” reinstall ëª…ë ¹ì–´ê°€ ìˆë‹¤ë©´
            return {"success": False, "msg": "Reinstall script is not existed"}

        # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        result = subprocess.run(
            [install_script, "--fresh"],  # ë˜ëŠ” ì ì ˆí•œ ì˜µì…˜
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )

        if result.returncode == 0:
            logging.info("âœ… SmartSystem install script completed")
            return {"success": True}
        else:
            logging.error(f"âŒ Install script failed: {result.stderr}")
            return {"success": False, "msg": result.stderr}

    except subprocess.TimeoutExpired:
        logging.error("âŒ Install script timeout")
        return {"success": False, "msg": "Install script timeout"}
    except Exception as e:
        logging.error(f"âŒ Install script error: {e}")
        return {"success": False, "msg": str(e)}


def delete_channel_data():
    """
    ch1, ch2ì˜ waveformê³¼ event íŒŒì¼ ì‚­ì œ (ê°„ë‹¨ ë²„ì „)
    """
    base_path = "/home/root"
    directories_to_clean = [
        "ch1/waveform",
        "ch1/event",
        "ch2/waveform",
        "ch2/event"
    ]

    total_deleted = 0

    try:
        for dir_path in directories_to_clean:
            full_path = os.path.join(base_path, dir_path)

            if not os.path.exists(full_path):
                continue

            for root, dirs, files in os.walk(full_path, topdown=False):
                for filename in files:
                    try:
                        os.remove(os.path.join(root, filename))
                        total_deleted += 1
                    except:
                        pass

        logging.info(f"âœ… Deleted {total_deleted} channel data files")
        return {"success": True, "deleted": total_deleted}

    except Exception as e:
        logging.error(f"âŒ Failed to delete channel data: {e}")
        return {"success": False, "msg": str(e)}


@router.get('/ResetAll')
async def resetAll(request:Request):
    # 1. stop service core and delete ntek 2. stop service SmartSystem 3. clear service SmartSystem and delete ssdb,ssdbnr 4. Clear count, 5. Delete setup, 6. Delete user.db
    saveLog("Factory Default", request)
    msg = ''
    if not redis_state.client is None:
        # redis_state.client.execute_command("SELECT", 0)
        if redis_state.client.hexists("Service", "setting"):
            checkflag = redis_state.client.hget("Service", "setting")
            if int(checkflag) == 1:
                return {"success": False, "msg": "Modbus setting is activated"}
        ret = await reset_system(request) #stop core, reinstall smartsystem
        if not ret["success"]:
            return ret
        setting_path = os.path.join(SETTING_FOLDER, 'setup.json')
        db_path = os.path.join(SETTING_FOLDER, 'user.db')
        bearing_db_path = os.path.join(SETTING_FOLDER, 'bearing.db')
        mt_path = os.path.join(SETTING_FOLDER, 'maintenance.db')
        backup_file_path = os.path.join(SETTING_FOLDER, 'setup_backup.json')
        try:
            if os.path.exists(setting_path):
                shutil.copy(setting_path, backup_file_path)  # setup.jsonì„ setting_backup.jsonìœ¼ë¡œ ë°±ì—…
                os.remove(setting_path)
            else:
                msg = "No exist setup.json"
            if os.path.exists(db_path):
                os.remove(db_path)
            else:
                msg += "No exist user.db"
            if os.path.exists(bearing_db_path):
                os.remove(bearing_db_path)
            if os.path.exists(mt_path):
                os.remove(mt_path)

            default_file_path = os.path.join(SETTING_FOLDER, 'default.json')

            with open(default_file_path, "r", encoding="utf-8") as f:
                defaults = json.load(f)

            defaults["mode"] = 'device0'
            defaults["General"]["deviceInfo"]["mac_address"] = ""
            defaults["General"]["deviceInfo"]["serial_number"] = ""

            with open(default_file_path, "w", encoding="utf-8") as f:
                json.dump(defaults, f, indent=2)  # indent ì¶”ê°€ë¡œ ê°€ë…ì„± í–¥ìƒ

            if redis_state.client.hexists("System", "setup"):
                redis_state.client.hdel("System", "setup")
            if redis_state.client.hexists("System", "mode"):
                redis_state.client.hdel("System", "mode")
            if redis_state.client.exists("Equipment"):
                redis_state.client.delete("Equipment")
            rt = delete_channel_data()
            sysService("start", "Core")
            if service_exists("smartsystemsservice.service"):
                sysService("start", "SmartSystems")
                sysService("start", "SmartAPI")
        except Exception as e:
            print(str(e))
            return {"success": False, "msg": str(e)}
    else:
        msg += "No saved setup in Redis"
    if msg == '':
        return {"success": True, "msg": "Reset success"}
    else:
        return {"success": True, "msg": msg}


@router.get('/getDiagnosisSetting')
async def get_diagnosissetting(request:Request):
    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getSettings")
        data = response.json()

    if data:
        # print(data)
        return {"success": True, "data": data}
    else:
        return {"success": False, "error": "No Data"}

@router.get('/getDiagnosisProfile')
async def get_diagnosisprofile(request:Request):

    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getProfile")
        data = response.json()

    if data:
        return {"success": True, "data": data}
    else:
        return {"success": False, "error": "No Data"}

@router.post('/setDiagnosisSetting')
async def set_diagnosissetting(request: Request):
    data = await request.json()
    status = 0
    if not data:
        return {"status": "1", "success": False, "error": ["No data provided"]}
    try:

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(f"http://{os_spec.restip}:5000/api/setSettings", json=data)
            data = response.json()

    except Exception as e:
        print("Error:", e)
        return {"status": "0", "success": False, "error": [str(e)]}

    if data:
        if data["Status"] == 0:
            return {"status": "1", "success": True }
        else:
            return {"status": "1", "success": False, "error": data["Messages"]}
    else:
        return {"status": "1", "success": False, "error": ["Save failed in setSettings API"]}

@router.post('/setDiagnosisProfile')
async def set_diagnosisprofile(request: Request):
    data = await request.json()
    if not data:
        return {"status": "1", "success": False, "error": ["No data provided"]}
    try:

        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(f"http://{os_spec.restip}:5000/api/setProfile", json=data)
            data = response.json()

    except Exception as e:
        print("Error:", e)
        return {"status": "0", "success": False, "error": [str(e)]}

    if data:
        if data["Status"] == 0:
            return {"status": "1", "success": True }
        else:
            return {"status": "1", "success": False, "error": data["Messages"]}
    else:
        return {"status": "1", "success": False, "error": ["Save Failed in setProfile API"]}

@router.get("/getAssetTypes")  # Diagnosis, Report Vue : get Asset info
async def get_assetTypes(request: Request):

    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getAssetTypes")
        data = response.json()

    if data:
        return {"success": True, "data": data}
    else:
        return {"success": False, "error": "No Data"}

@router.get('/getAssetList')
async def get_assetlist(request: Request):

    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getAssetHierarchy")
        datas = response.json()


    if len(datas) > 0:
        grouped = defaultdict(list)
        for item in datas:
            aid = item["AssemblyType"]
            if aid is not None and aid != "null" and item["AssemblyID"] !="null" and item["Name"] !="Plant":
                grouped[aid].append({
                    "Name": item["Name"],
                    "Type": aid
                })
        return {'success': True, "data":grouped}
    else:
        return {'success': False, "msg": 'No exist assets'}

@router.post('/upload')  # upload setup.json
def upload_file(file: UploadFile = File(...)):
    if file.filename == '':
        return {'passOK': '0', 'error': 'No selected file'}

    # ê¸°ì¡´ setup.json íŒŒì¼ ê²½ë¡œ
    original_file_path = os.path.join(SETTING_FOLDER, 'setup.json')
    backup_file_path = os.path.join(SETTING_FOLDER, 'setup_backup.json')

    try:

        
        # ê¸°ì¡´ setup.json íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë°±ì—…
        if os.path.exists(original_file_path):
            shutil.copy(original_file_path, backup_file_path)  # setup.jsonì„ setting_backup.jsonìœ¼ë¡œ ë°±ì—…

        # ì—…ë¡œë“œëœ íŒŒì¼ì„ setup.jsonìœ¼ë¡œ ì €ì¥
        with open(original_file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        file.file.seek(0)  # ë‹¤ì‹œ ì½ê¸° ìœ„í•´ ì»¤ì„œ ì´ˆê¸°í™”
        file_content = file.file.read().decode("utf-8")

        # Redisì— ê·¸ëŒ€ë¡œ ë¬¸ìì—´ë¡œ ì €ì¥
        # redis_state.client.execute_command("SELECT", 0)
        redis_state.client.hset("System", "setup", file_content)
        redis_state.client.hset("Service", "save", 1)
        redis_state.client.hset("Service", "restart", 1)
        return {'passOK': '1', 'file_path': original_file_path}

    except Exception as e:
        return {'passOK': '0', 'error': str(e)}

@router.get('/checkBearing')
def load_bearings_from_db():
    """DBì—ì„œ Bearing ë°ì´í„° ë¡œë“œ"""
    try:
        # DB ê²½ë¡œ í™•ì¸
        print(f"DB Path: {BEARINGDB_PATH}")
        
        # DB ì´ˆê¸°í™” (í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±)
        conn = sqlite3.connect(str(BEARINGDB_PATH))
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS bearings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                Name TEXT UNIQUE NOT NULL,
                BPFO REAL NOT NULL,
                BPFI REAL NOT NULL,
                BSF REAL NOT NULL,
                FTF REAL NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        
        # ë°ì´í„° ì¡°íšŒ
        cursor.execute('SELECT Name, BPFO, BPFI, BSF, FTF FROM bearings ORDER BY Name')
        rows = cursor.fetchall()
        
        # ìˆ˜ë™ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ ë³€í™˜
        result = []
        for row in rows:
            result.append({
                'Name': row[0],
                'BPFO': float(row[1]),
                'BPFI': float(row[2]),
                'BSF': float(row[3]),
                'FTF': float(row[4])
            })
        
        conn.close()
        
        print(f"Loaded {len(result)} bearings from DB")
        
        if len(result) == 0:
            return {'passOK': '1', 'data': [], 'msg': 'No bearing data in database'}
        
        return {'passOK': '1', 'data': result}
        
    except Exception as e:
        print(f"DB Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {'passOK': '0', 'msg': f'Database error: {str(e)}'}

def init_bearing_db_from_csv():
    """ì´ˆê¸° Bearing DB íŒŒì¼(NTEKBearingDB.csv)ì„ DBì— ì—…ë¡œë“œ"""
    try:
        logging.info("ğŸ”„ Starting bearing DB initialization...")
        
        # âœ… 1. DB ì—°ê²° ë° í…Œì´ë¸” ìƒì„± (ë¨¼ì €!)
        conn = sqlite3.connect(str(BEARINGDB_PATH))
        cursor = conn.cursor()
        
        logging.info(f"ğŸ“‚ DB Path: {BEARINGDB_PATH}")
        
        # âœ… í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS bearings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                Name TEXT UNIQUE NOT NULL,
                BPFO REAL NOT NULL,
                BPFI REAL NOT NULL,
                BSF REAL NOT NULL,
                FTF REAL NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        logging.info("âœ… Bearing table created/verified")
        
        # âœ… 2. íŒŒì¼ ê²½ë¡œ í™•ì¸
        bearing_file = SETTING_FOLDER / "NTEKBearingDB.csv"
        logging.info(f"ğŸ“‚ CSV Path: {bearing_file}")
        
        if not bearing_file.exists():
            conn.close()
            logging.warning(f"âš ï¸ NTEKBearingDB.csv not found at {bearing_file}")
            return {'success': False, 'msg': 'NTEKBearingDB.csv file not found'}
        
        # âœ… 3. íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸°
        data = get_Bearing(str(bearing_file))
        
        if not data or len(data) == 0:
            conn.close()
            logging.warning("âš ï¸ No bearing data in file")
            return {'success': False, 'msg': 'No bearing data in file'}
        
        logging.info(f"ğŸ“‹ Parsed {len(data)} bearings from CSV")
        
        # âœ… 4. ë°ì´í„° ì‚½ì…
        inserted_count = 0
        skipped_count = 0
        
        for bearing in data:
            try:
                name = str(bearing.get('Name', ''))
                bpfo = float(bearing.get('BPFO', 0))
                bpfi = float(bearing.get('BPFI', 0))
                bsf = float(bearing.get('BSF', 0))
                ftf = float(bearing.get('FTF', 0))
                
                cursor.execute('''
                    INSERT INTO bearings (Name, BPFO, BPFI, BSF, FTF)
                    VALUES (?, ?, ?, ?, ?)
                ''', (name, bpfo, bpfi, bsf, ftf))
                
                inserted_count += 1
                
            except sqlite3.IntegrityError:
                skipped_count += 1
                continue
            except Exception as e:
                logging.error(f"Error inserting bearing {bearing.get('Name')}: {e}")
                continue
        
        conn.commit()
        conn.close()
        
        logging.info(f"âœ… Bearing DB initialized: {inserted_count} inserted, {skipped_count} skipped")
        
        return {
            'success': True,
            'inserted': inserted_count,
            'skipped': skipped_count,
            'msg': f'Successfully initialized bearing database'
        }
        
    except Exception as e:
        logging.error(f"âŒ Bearing DB initialization error: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'msg': str(e)}
      
@router.post('/uploadBearing')
def upload_bearing_to_db(file: UploadFile = File(...)):
    """ì—…ë¡œë“œëœ Bearing íŒŒì¼ì„ DBì— ì €ì¥"""
    if file.filename == '':
        return {'passOK': '0', 'error': 'No selected file'}

    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file_path = os.path.join(SETTING_FOLDER, file.filename)
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸°
        data = get_Bearing(temp_file_path)
        
        print(f"Parsed {len(data)} bearings from file")
        
        # DBì— ì‚½ì…
        conn = sqlite3.connect(str(BEARINGDB_PATH))
        cursor = conn.cursor()
        
        inserted = []
        skipped = []
        
        for bearing in data:
            try:
                # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
                name = str(bearing.get('Name', ''))
                bpfo = float(bearing.get('BPFO', 0))
                bpfi = float(bearing.get('BPFI', 0))
                bsf = float(bearing.get('BSF', 0))
                ftf = float(bearing.get('FTF', 0))
                
                cursor.execute('''
                    INSERT INTO bearings (Name, BPFO, BPFI, BSF, FTF)
                    VALUES (?, ?, ?, ?, ?)
                ''', (name, bpfo, bpfi, bsf, ftf))
                
                inserted.append({
                    'Name': name,
                    'BPFO': bpfo,
                    'BPFI': bpfi,
                    'BSF': bsf,
                    'FTF': ftf
                })
                print(f"Inserted: {name}")
                
            except sqlite3.IntegrityError:
                skipped.append(bearing.get('Name', 'Unknown'))
                print(f"Skipped (duplicate): {bearing.get('Name', 'Unknown')}")
                continue
            except Exception as e:
                print(f"Error inserting bearing: {e}")
                continue
        
        conn.commit()
        conn.close()
        
        print(f"Total inserted: {len(inserted)}, Skipped: {len(skipped)}")
        
        # íŒŒì¼ì„ ë‚ ì§œì™€ í•¨ê»˜ ë°±ì—… ì €ì¥
        if os.path.exists(temp_file_path):
            # í˜„ì¬ ë‚ ì§œ/ì‹œê°„ (YYYYMMDD_HHMMSS í˜•ì‹)
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H")
            
            # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬
            file_base, file_ext = os.path.splitext(file.filename)
            
            # ìƒˆ íŒŒì¼ëª…: ì›ë³¸íŒŒì¼ëª…_YYYYMMDD_HHMMSS.í™•ì¥ì
            backup_filename = f"{file_base}_{timestamp}{file_ext}"
            backup_path = os.path.join(SETTING_FOLDER, backup_filename)
            
            # íŒŒì¼ ë³µì‚¬ (ì´ë™ì´ ì•„ë‹Œ ë³µì‚¬)
            shutil.copy(temp_file_path, backup_path)
            print(f"Backup saved: {backup_filename}")
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.remove(temp_file_path)
        
        if len(inserted) == 0 and len(skipped) > 0:
            return {
                'passOK': '1', 
                'data': [], 
                'msg': f'All {len(skipped)} bearings already exist in database'
            }
        
        return {
            'passOK': '1', 
            'data': inserted, 
            'inserted': len(inserted),
            'skipped': len(skipped)
        }

    except Exception as e:
        print(f"Upload Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {'passOK': '0', 'error': str(e)}

def init_bearing_db():
    """Bearing ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    conn = sqlite3.connect(BEARINGDB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS bearings (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            Name TEXT UNIQUE NOT NULL,
            BPFO REAL NOT NULL,
            BPFI REAL NOT NULL,
            BSF REAL NOT NULL,
            FTF REAL NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()

def get_all_bearings():
    """DBì—ì„œ ëª¨ë“  Bearing ë°ì´í„° ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(BEARINGDB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('SELECT Name, BPFO, BPFI, BSF, FTF FROM bearings ORDER BY Name')
        rows = cursor.fetchall()
        
        result = [dict(row) for row in rows]
        conn.close()
        
        return result
    except Exception as e:
        print(f"DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return []

def insert_bearings(bearing_list):
    """ìƒˆë¡œìš´ Bearing ë°ì´í„°ë¥¼ DBì— ì‚½ì… (ì¤‘ë³µ ì œì™¸)"""
    try:
        conn = sqlite3.connect(BEARINGDB_PATH)
        cursor = conn.cursor()
        
        inserted = []
        for bearing in bearing_list:
            try:
                cursor.execute('''
                    INSERT INTO bearings (Name, BPFO, BPFI, BSF, FTF)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    bearing['Name'],
                    float(bearing['BPFO']),
                    float(bearing['BPFI']),
                    float(bearing['BSF']),
                    float(bearing['FTF'])
                ))
                inserted.append(bearing)
            except sqlite3.IntegrityError:
                # ì¤‘ë³µëœ Nameì€ ë¬´ì‹œ
                continue
        
        conn.commit()
        conn.close()
        
        return inserted
    except Exception as e:
        print(f"DB ì‚½ì… ì˜¤ë¥˜: {e}")
        return []
@router.get('/download')  # download setup.json
def download_setting():
    file_path = os.path.join(SETTING_FOLDER, 'setup.json')

    # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
    if not os.path.exists(file_path):
        return {"passOK": "0", "error": "setting file not found"}

    try:
        # íŒŒì¼ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
        response = FileResponse(file_path, media_type="application/json", filename="setup.json")
        response.headers["Content-Disposition"] = "attachment; filename=setup.json"  # ë‹¤ìš´ë¡œë“œ ê°•ì œ
        return response
    except Exception as e:
        return {"passOK": "0", "error": f"An unexpected error occurred: {str(e)}"}


async def reset_smart(asset, mode):
    if mode == 0:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/unregisterAsset?name={asset}")
            data = response.json()
    else:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/deleteAsset?name={asset}")
            data = response.json()
    return data


@router.post('/createAsset')
async def createAsset(request: Request):
    data = await request.json()

    if not data:
        return {"status": "0", "error": "No data provided"}
    assetType = data['assetType']
    assetName = data['assetName']
    print("assetType",assetType,"assetName",assetName)
    try:
        # response = await  http_state.client.get(f"/createAsset?type={assetType}&name={assetName}")
        # datas = response.json()
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/createAsset?type={assetType}&name={assetName}")
            datas = response.json()
        #     if response.status_code in [400, 401, 500]:
        #         flag = await checkLoginAPI(request)
        #         if not flag:
        #             return {"success": False, "error": "Restful API Login Failed"}
        #         else:
        #             response = await client.get(f"http://{os_spec.restip}:5000/api/createAsset?type={assetType}&name={assetName}")
        #             datas = response.json()
    except Exception as e:
        print(str(e))
        return {"status": "0", "error": "Created Failed"}

    if datas:
        if datas["Status"] == 0:
            return {"status": "1"}
        else:
            return {"status": "0", "error": "Create Failed"}  # ì„±ê³µí•´ë„ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¶”ê°€ì•ˆëœìƒíƒœë¡œ ë¦¬í„´ë˜ì„œ ì—¬ê¸°ë¡œë¹ ì§
    else:
        return {"status": "0", "error": "Create Failed"}
    # if len(datas) > 0:
    #     if assetName in datas:
    #         return {"status": "1"}
    #     else:
    #         return {"status": "0", "error": "Create Failed"} #ì„±ê³µí•´ë„ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¶”ê°€ì•ˆëœìƒíƒœë¡œ ë¦¬í„´ë˜ì„œ ì—¬ê¸°ë¡œë¹ ì§
    # else:
    #     return {"status": "0", "error": "Create Failed"}

@router.post('/modifyAsset')
async def modifyAsset(request: Request):
    data = await request.json()
    if not data:
        return {"status": "0", "error": "No data provided"}
    assetName = data.get("assetName") 
    newName = data.get("newName")
    try:
        # response = await  http_state.client.get(f"/renameAsset?name={assetName}&newname={newName}")
        # datas = response.json()
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/renameAsset?name={assetName}&newname={newName}")
            datas = response.json()
        #     if response.status_code in [400, 401, 500]:
        #         flag = await checkLoginAPI(request)
        #         if not flag:
        #             return {"success": False, "error": "Restful API Login Failed"}
        #         else:
        #             response = await client.get(f"http://{os_spec.restip}:5000/api/renameAsset?name={assetName}&newname={newName}")
        #             datas = response.json()
    except Exception as e:
        return {"status": "0", "error": "Modify Failed"}

    if datas:
        if datas["Status"] == 0:
            return {"status": "1"}
        else:
            return {"status": "0", "error": "Modify Failed"}  # ì„±ê³µí•´ë„ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¶”ê°€ì•ˆëœìƒíƒœë¡œ ë¦¬í„´ë˜ì„œ ì—¬ê¸°ë¡œë¹ ì§
    else:
        return {"status": "0", "error": "Modify Failed"}
    # if len(datas) > 0:
    #     if newName in datas:
    #         return {"status": "1"}
    #     else:
    #         return {"status": "0", "error": "Modify Failed"}
    # else:
    #     return {"status": "0", "error": "Modify Failed"}

@router.get('/deleteAsset/{asset}')
async def deleteAsset(asset):
    try:
        datas = await reset_smart(asset, 1)
        # async with httpx.AsyncClient(timeout=setting_timeout) as client:
        #     response = await client.get(f"http://{os_spec.restip}:5000/api/deleteAsset?name={asset}")
        #     datas = response.json()
    except Exception as e:
        print(str(e))
        return {"status": "0", "error": "Delete Failed"}

    if datas:
        if datas["Status"] == 0:
            return {"status": "1"}
        else:
            return {"status": "0", "error": "Delete Failed"}  # ì„±ê³µí•´ë„ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¶”ê°€ì•ˆëœìƒíƒœë¡œ ë¦¬í„´ë˜ì„œ ì—¬ê¸°ë¡œë¹ ì§
    else:
        return {"status": "0", "error": "Delete Failed"}

    # if len(datas) > 0:
    #     if not asset in datas:
    #         return {"status": "1"}
    #     else:
    #         return {"status": "0", "error": "Delete Failed"}
    # else:
    #     return {"status": "1"}

@router.get('/unregisterAsset/{channel}/{asset}')
async def unreg_Asset(channel, asset):
    # async with httpx.AsyncClient(timeout=setting_timeout) as client:
    #     response = await client.get(f"http://{os_spec.restip}:5000/api/unregisterAsset?name={asset}")
    #     data = response.json()
    data = await reset_smart(asset, 0)
    # remove_applyStatus(channel, asset)
    if isinstance(data, list) and len(data) > 0:
        finflag = True
    else:
        finflag = False
    # redis_state.client.execute_command("SELECT", 0)
    if redis_state.client.hexists("System","setup"):
        datStr = redis_state.client.hget("System","setup")
        setting = json.loads(datStr)
        for chInfo in setting["channel"]:
            if channel == chInfo["channel"]:
                chInfo["assetInfo"]["name"] =''
                chInfo["assetInfo"]["type"] = ''
                finflag = True
                break
        redis_state.client.hset("System","setup", json.dumps(setting))
    if finflag:
        return {"success":True}
    else:
        return {"success":False}


@router.get('/registerAsset/{channel}/{assetName}/{assetType}')
async def reg_Asset(channel, assetName, assetType):
    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/registerAsset?name={assetName}")
        data = response.json()
    if isinstance(data, list) and len(data) > 0:
        finflag = True
    else:
        finflag = False
    # redis_state.client.execute_command("SELECT", 0)
    if redis_state.client.hexists("System","setup"):
        datStr = redis_state.client.hget("System","setup")
        setting = json.loads(datStr)
        for chInfo in setting["channel"]:
            if channel == chInfo["channel"]:
                chInfo["assetInfo"]["name"] = assetName
                chInfo["assetInfo"]["type"] = assetType
                finflag = True
                break
        redis_state.client.hset("System","setup", json.dumps(setting))

        # set_applyStatus(channel, assetName)
    if finflag:
        return {"success":True}
    else:
        return {"success":False}

# def make_applyStatus():
#     equipStatus = {
#         "restartFW": False,
#         "commisionAsset": {
#             "Main": {
#                 "Name": '',
#                 "result": False,
#             },
#             "Sub": {
#                 "Name": '',
#                 "result": False,
#             }
#         }
#     }
#     return equipStatus

# def set_applyStatus(channel, assetName):
#     if redis_state.client.hexists("Equipment", "applyStatus"):
#         applyst = redis_state.client.hget("Equipment", "applyStatus")
#         equipStatus = json.loads(applyst)
#     else:
#         equipStatus = make_applyStatus()
#     if equipStatus["commisionAsset"].get(channel):
#         if equipStatus["commisionAsset"][channel]["Name"] == '':
#             equipStatus["commisionAsset"][channel]["Name"] = assetName
#             equipStatus["commisionAsset"][channel]["result"] = False
#         elif equipStatus["commisionAsset"][channel]["Name"] == assetName:
#             equipStatus["commisionAsset"][channel]["result"] = False
#     else:
#         equipStatus["commisionAsset"][channel] = {
#             "Name": assetName,
#             "result": False
#         }
#     redis_state.client.hset("Equipment", "applyStatus", json.dumps(equipStatus))
#
#
# def remove_applyStatus(channel, assetName):
#     if redis_state.client.hexists("Equipment", "applyStatus"):
#         applyst = redis_state.client.hget("Equipment", "applyStatus")
#         equipStatus = json.loads(applyst)
#
#         if equipStatus["commisionAsset"].get(channel):
#             if equipStatus["commisionAsset"][channel]["Name"] == assetName:
#                 equipStatus["commisionAsset"][channel]["Name"] = ''
#                 equipStatus["commisionAsset"][channel]["result"] = False
#
#         redis_state.client.hset("Equipment", "applyStatus", json.dumps(equipStatus))

def save_alarm_configs_to_redis(setting_dict: dict):
    dash_alarms_data = {}

    # ê° ì±„ë„ ìˆœíšŒ
    for channel_config in setting_dict.get("channel", []):
        channel_name = channel_config.get("channel")
        asset_info = channel_config.get("assetInfo", {})
        status_info = channel_config.get("status_Info", {})
        # use_do = channel_config.get("useDO", 0)  # ì±„ë„ë³„ useDO
        confStatus = channel_config.get("confStatus", 0)  # ì±„ë„ë³„ useDO
        if not channel_name:
            continue

        # useDOê°€ 0ì´ë©´ í•´ë‹¹ ì±„ë„ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©)
        if confStatus == 0:
            continue

        # ì±„ë„ë³„ DashAlarms ë°ì´í„°
        dash_alarms_data[channel_name] = {
            "assetType": asset_info.get("type", ""),
            "assetName": asset_info.get("name", ""),
            "assetNickName": asset_info.get("nickname", ""),
            "diagnosis": status_info.get("diagnosis", []),
            "pq": status_info.get("pq", [])
        }

    return dash_alarms_data

def save_ai_configs_to_redis(setting_dict: dict):
    ai_data = {}

    # ê° ì±„ë„ ìˆœíšŒ
    for channel_config in setting_dict.get("channel", []):
        channel_name = channel_config.get("channel")
        status_info = channel_config.get("ai_modbus", [])
        # use_do = channel_config.get("useDO", 0)  # ì±„ë„ë³„ useDO
        confStatus = channel_config.get("useAI", 0)  # ì±„ë„ë³„ useDO
        if not channel_name:
            continue

        # useDOê°€ 0ì´ë©´ í•´ë‹¹ ì±„ë„ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©)
        if confStatus == 0:
            continue

        # ì±„ë„ë³„ DashAlarms ë°ì´í„°
        ai_data[channel_name] = [item for item in status_info if item.get("enable") == 1]

    return ai_data


def initialize_alarm_configs(channel, alams):
    rediskey = f"alarm_status:{channel}"
    alarmdict = {}
    for j in range(1, 33):
        if alams[str(j)][0] != 0:
            alarmdict[str(j)] = alams[str(j)]
    if len(alarmdict.keys()) > 0:
        # redis_state.client_db1.execute_command("SELECT", 1)
        redis_state.client_db1.delete(rediskey)
        for key in alarmdict:
            if alarmdict[key][1] == 0:
                condstr = 'UNDER'
            else:
                condstr = 'OVER'
            init_data = {
                "status": 0,
                "count": 0,
                "condition": condstr,
                "value": 0,
                "chan": alarmdict[key][0],
                "cond": alarmdict[key][1],
                "level": alarmdict[key][3],
                "chan_text": parameter_options[alarmdict[key][0]],
                "last_update": int(datetime.now().timestamp()),
                "status_text": "None"
            }
            redis_state.client_db1.hset(rediskey, key, json.dumps(init_data))

@router.post('/savefile/{channel}')  # save setup.json
async def saveSetting(channel: str, request: Request):
    deviceMac = get_mac_address()
    ser=''
    ctSetup = {}
    if os_spec.os != 'Windows':
        mac_file_path = os.path.join(SETTING_FOLDER, 'serial_num_do_not_modify.txt')
        if os.path.exists(mac_file_path):
            ser = read_mac_plain(mac_file_path)
            # if ser != deviceMac:
            #     deviceMac = ser
    # redis_state.client.select(0)
    if redis_state.client.hexists("Service","setting"):
        checkflag = redis_state.client.hget("Service","setting")
        if int(checkflag) == 1:
            return {"status": "0", "error": "Modbus setting is activated"}
    try:
        FILE_PATH = os.path.join(SETTING_FOLDER, "setup.json")
        #FTP_PATH = os.path.join(SETTING_FOLDER, "WaveformFTP.json")
        # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° JSON ë°ì´í„° ë°›ê¸°
        data = await request.json()
        if not data:
            return {"status": "0", "error": "No data provided"}

        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì½ê¸°, ì—†ìœ¼ë©´ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
        if os.path.exists(FILE_PATH):
            with open(FILE_PATH, "r", encoding="utf-8") as f:
                setting = json.load(f)
        else:
            # ê¸°ë³¸ JSON êµ¬ì¡° (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
            setting = {"mode": "device", "General": {}, "channel": []}

        # ì±„ë„ íŒŒë¼ë¯¸í„°ê°€ "general"ì´ë©´ "General" ë¶€ë¶„ ì—…ë°ì´íŠ¸
        if channel.lower() == "general":        
            setting["General"] = data
        # elif channel.lower() == "status":
        #     setting["status_Info"] = data
        else:
            # ê·¸ ì™¸ì˜ ê²½ìš°, "channel" ë°°ì—´ ë‚´ì—ì„œ í•´ë‹¹ ì±„ë„ ì—…ë°ì´íŠ¸ (ì—†ìœ¼ë©´ ì¶”ê°€)
            if "channel" not in setting or not isinstance(setting["channel"], list):
                setting["channel"] = []
            updated = False
            for idx, ch in enumerate(setting["channel"]):
                if ch.get("channel", "").lower() == channel.lower():
                    setting["channel"][idx] = data
                    updated = True
                    setting["channel"][idx]["ctInfo"]["inorminal"] = int(float(data["ctInfo"]["inorminal"])*1000)
                    break
            if not updated:
                setting["channel"].append(data)

        # ì—…ë°ì´íŠ¸ëœ ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥ (ë®ì–´ì“°ê¸°)
        if deviceMac != setting["General"]["deviceInfo"]["mac_address"]:
            setting["General"]["deviceInfo"]["mac_address"] = deviceMac
            # setting["General"]["deviceInfo"]["serial_number"] = deviceMac
        if ser != '':
            setting["General"]["deviceInfo"]["serial_number"] = ser
        else:
            setting["General"]["deviceInfo"]["serial_number"] = deviceMac

        with open(FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(setting, f, indent=4)

        if len(setting["channel"]) > 0:
            for i in range(0,len(setting["channel"])):
                initialize_alarm_configs(setting["channel"][i]["channel"], setting["channel"][i]["alarm"])

        # redis_state.client.select(0)
        saveCurrent = saveStartCurrent(setting)
        dash_alarms_data = save_alarm_configs_to_redis(setting)
        redis_state.client.hset("System", "setup", json.dumps(setting))
        redis_state.client.hset("Equipment", "StartingCurrent", json.dumps(saveCurrent))
        if dash_alarms_data:
            redis_state.client.hset("Equipment", "DashAlarms", json.dumps(dash_alarms_data))
        else:
            redis_state.client.hdel("Equipment", "DashAlarms")
        return {"status": "1", "data": setting}
    except Exception as e:
        print("Error:", e)
        return {"status": "0", "error": str(e)}

def compare_channel_changes(redis_data: dict, post_data: dict) -> Dict[str, Any]:
    result = {
        "General": {"status": "no_change", "changed_fields": []},
        "Main": {"status": "disabled", "changed_fields": []},
        "Sub": {"status": "disabled", "changed_fields": []}
    }

    # General ë¹„êµ - ëª¨ë“  í•„ë“œ ì²´í¬
    redis_general = redis_data.get("General", {})
    post_general = post_data.get("General", {})

    general_fields_to_compare = [
        "va_type", "pf_sign", "unbalance",
        "deviceInfo", "tcpip", "modbus",
        "useFuction", "ftpInfo", "sntpInfo"
    ]

    general_changed_fields = []
    for field in general_fields_to_compare:
        redis_val = redis_general.get(field)
        post_val = post_general.get(field)

        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ê¹Šì€ ë¹„êµ
        if isinstance(redis_val, dict) and isinstance(post_val, dict):
            if redis_val != post_val:
                general_changed_fields.append(field)
        elif redis_val != post_val:
            general_changed_fields.append(field)

    if general_changed_fields:
        result["General"]["status"] = "config_changed"
        result["General"]["changed_fields"] = general_changed_fields

    # Channel ë¹„êµ
    redis_channels = {ch["channel"]: ch for ch in redis_data.get("channel", [])}
    post_channels = {ch["channel"]: ch for ch in post_data.get("channel", [])}

    channel_fields_to_compare = [
        "Enable", "PowerQuality", "ctInfo", "ptInfo", "assetInfo",
        "eventInfo", "sampling", "demand", "trendInfo", "alarm",
        "n_kva", "confStatus","status_Info", "useDO", "useAI", "ai_modbus"
    ]

    for channel_name in ["Main", "Sub"]:
        redis_ch = redis_channels.get(channel_name, {})
        post_ch = post_channels.get(channel_name, {})

        if post_ch.get("Enable") != 1:
            continue

        changed_fields = []
        for field in channel_fields_to_compare:
            redis_val = redis_ch.get(field)
            post_val = post_ch.get(field)

            # ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¹Šì€ ë¹„êµ
            if isinstance(redis_val, (dict, list)) and isinstance(post_val, (dict, list)):
                if redis_val != post_val:
                    changed_fields.append(field)
            elif redis_val != post_val:
                changed_fields.append(field)

        result[channel_name]["changed_fields"] = changed_fields

        if not changed_fields:
            result[channel_name]["status"] = "no_change"
        elif changed_fields == ["assetInfo"]:
            result[channel_name]["status"] = "asset_only"
        else:
            result[channel_name]["status"] = "config_changed"

    return result


# @router.post('/savefileNew')  # â­ {channel} ì œê±°
# async def saveSetting2(request: Request):
#     deviceMac = get_mac_address()
#     ser = ''
#
#     if os_spec.os != 'Windows':
#         mac_file_path = os.path.join(SETTING_FOLDER, 'serial_num_do_not_modify.txt')
#         if os.path.exists(mac_file_path):
#             ser = read_mac_plain(mac_file_path)
#
#     # redis_state.client.select(0)
#     if redis_state.client.hexists("Service", "setting"):
#         checkflag = redis_state.client.hget("Service", "setting")
#         if int(checkflag) == 1:
#             return {"status": "0", "error": "Modbus setting is activated"}
#
#     try:
#         FILE_PATH = os.path.join(SETTING_FOLDER, "setup.json")
#
#         # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ì „ì²´ ì„¤ì • ë°ì´í„° ë°›ê¸°
#         data = await request.json()
#         if not data:
#             return {"status": "0", "error": "No data provided"}
#
#         # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
#         if "General" not in data:
#             data["General"] = {}
#         if "channel" not in data or not isinstance(data["channel"], list):
#             data["channel"] = []
#
#         # MAC ì£¼ì†Œ ë° ì‹œë¦¬ì–¼ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
#         if "deviceInfo" not in data["General"]:
#             data["General"]["deviceInfo"] = {}
#
#         data["General"]["deviceInfo"]["mac_address"] = deviceMac
#
#         if ser != '':
#             data["General"]["deviceInfo"]["serial_number"] = ser
#         else:
#             data["General"]["deviceInfo"]["serial_number"] = deviceMac
#
#         # ê° ì±„ë„ì˜ ctInfo.inorminal ê°’ ì²˜ë¦¬
#
#         for ch in data["channel"]:
#             if "ctInfo" in ch and "inorminal" in ch["ctInfo"]:
#                 ch["ctInfo"]["inorminal"] = int(float(ch["ctInfo"]["inorminal"]) * 1000)
#
#
#         prevSetup = redis_state.client.hget("System", "setup")
#         prevData = json.loads(prevSetup)
#
#         # íŒŒì¼ì— ì €ì¥
#         with open(FILE_PATH, "w", encoding="utf-8") as f:
#             json.dump(data, f, indent=4)
#
#         # ì•ŒëŒ ì„¤ì • ì´ˆê¸°í™”
#         if len(data["channel"]) > 0:
#             for ch in data["channel"]:
#                 if "channel" in ch and "alarm" in ch:
#                     initialize_alarm_configs(ch["channel"], ch["alarm"])
#
#         # Redisì— ì €ì¥
#         # saveCurrent = saveStartCurrent(data)
#         procData = save_StartCurrent_DemandInterval_SamplingPeriod(data)
#         dash_alarms_data = save_alarm_configs_to_redis(data)
#         result = compare_channel_changes(prevData, data)
#         restartAsset = False
#         restartdevice = False
#         if result["General"]["status"] == 'config_changed' or result["Main"]["status"] == 'config_changed' or result["Sub"]["status"] == 'config_changed':
#             restartdevice = True
#         elif result["Main"]["status"] == 'asset_only' or result["Sub"]["status"] == 'asset_only':
#             restartAsset = True
#
#         checkResult = check_ApplyStatus()
#
#         if not restartAsset:
#             commision_asset = checkResult.get("commisionAsset", {})
#
#             for channel in ["Main", "Sub"]:
#                 channel_data = commision_asset.get(channel, {})
#                 if channel_data.get("Name") and not channel_data.get("result", False):
#                     restartAsset = True
#                     break  # í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ ë°”ë¡œ ì¢…ë£Œ
#
#         if not restartdevice:
#             if not checkResult["restartFW"]:
#                 restartdevice = True
#
#         redis_state.client.hset("System", "setup", json.dumps(data))
#         redis_state.client.hset("Equipment", "StartingCurrent", json.dumps(procData["StartCurrent"]))
#         redis_state.client.hset("Equipment", "DemandInterval", json.dumps(procData["Demand"]))
#         redis_state.client.hset("Equipment", "SamplingPeriod", json.dumps(procData["Sampling"]))
#
#         if dash_alarms_data:
#             redis_state.client.hset("Equipment", "DashAlarms", json.dumps(dash_alarms_data))
#         else:
#             redis_state.client.hdel("Equipment", "DashAlarms")
#
#         return {"status": "1", "data": data, "restartDevice": restartdevice, "restartAsset": restartAsset}
#
#     except Exception as e:
#         print("Error:", e)
#         import traceback
#         traceback.print_exc()
#         return {"status": "0", "error": str(e)}

@router.post('/savefileNew')  # â­ {channel} ì œê±°
async def saveSetting2(request: Request):
    deviceMac = get_mac_address()
    ser = ''

    if os_spec.os != 'Windows':
        mac_file_path = os.path.join(SETTING_FOLDER, 'serial_num_do_not_modify.txt')
        if os.path.exists(mac_file_path):
            ser = read_mac_plain(mac_file_path)

    if redis_state.client.hexists("Service", "setting"):
        checkflag = redis_state.client.hget("Service", "setting")
        if int(checkflag) == 1:
            return {"status": "0", "error": "Modbus setting is activated"}

    try:

        data = await request.json()
        if not data:
            return {"status": "0", "error": "No data provided"}

        # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
        if "General" not in data:
            data["General"] = {}
        if "channel" not in data or not isinstance(data["channel"], list):
            data["channel"] = []

        # MAC ì£¼ì†Œ ë° ì‹œë¦¬ì–¼ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
        if "deviceInfo" not in data["General"]:
            data["General"]["deviceInfo"] = {}

        data["General"]["deviceInfo"]["mac_address"] = deviceMac

        if ser != '':
            data["General"]["deviceInfo"]["serial_number"] = ser
        else:
            data["General"]["deviceInfo"]["serial_number"] = deviceMac

        # ê° ì±„ë„ì˜ ctInfo.inorminal ê°’ ì²˜ë¦¬

        for ch in data["channel"]:
            if "ctInfo" in ch and "inorminal" in ch["ctInfo"]:
                ch["ctInfo"]["inorminal"] = int(float(ch["ctInfo"]["inorminal"]) * 1000)

        redis_state.client.hset("System", "config", json.dumps(data))
        return {"status": "1"}
    except Exception as e:
        print("Error:", e)
        import traceback
        traceback.print_exc()
        return {"status": "0", "error": str(e)}


@router.get('/apply')
def apply():
    if redis_state.client.hexists("Service", "setting"):
        checkflag = redis_state.client.hget("Service", "setting")
        if int(checkflag) == 1:
            return {"status": "0", "error": "Modbus setting is activated"}

    saveSetup = redis_state.client.hget("System", "config")
    saveData = json.loads(saveSetup)

    prevSetup = redis_state.client.hget("System", "setup")
    prevData = json.loads(prevSetup)

    FILE_PATH = os.path.join(SETTING_FOLDER, "setup.json")

    with open(FILE_PATH, "w", encoding="utf-8") as f:
        json.dump(saveData, f, indent=4)

    if len(saveData["channel"]) > 0:
        for ch in saveData["channel"]:
            if "channel" in ch and "alarm" in ch:
                initialize_alarm_configs(ch["channel"], ch["alarm"])

    procData = save_StartCurrent_DemandInterval_SamplingPeriod(saveData)
    dash_alarms_data = save_alarm_configs_to_redis(saveData)
    ai_data = save_ai_configs_to_redis(saveData)
    result = compare_channel_changes(prevData, saveData)

    restartdevice = False

    if result["General"]["status"] == 'config_changed' or result["Main"]["status"] == 'config_changed' or result["Sub"][
        "status"] == 'config_changed':
        restartdevice = True

    redis_state.client.hset("System", "setup", json.dumps(saveData))
    redis_state.client.hset("Equipment", "StartingCurrent", json.dumps(procData["StartCurrent"]))
    redis_state.client.hset("Equipment", "DemandInterval", json.dumps(procData["Demand"]))
    redis_state.client.hset("Equipment", "SamplingPeriod", json.dumps(procData["Sampling"]))
    redis_state.client.hset("Equipment", "ChannelData", json.dumps(procData["Channel"]))

    if dash_alarms_data:
        redis_state.client.hset("Equipment", "DashAlarms", json.dumps(dash_alarms_data))
    else:
        redis_state.client.hdel("Equipment", "DashAlarms")

    if ai_data:
        redis_state.client.hset("Equipment", "AIConfig", json.dumps(ai_data))
    else:
        redis_state.client.hdel("Equipment", "AIConfig")

    return {"status": "1", "data": saveData, "restartDevice": restartdevice}

@router.get('/checkCommision/{asset}')
async def check_comm(asset):
    try:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/iscommrequired?name={asset}")
            data = response.json()

        if data:
            return {"status": 1, "result": data["CommissioningRequired"]}
        else:
            return {"status": 0, "error": "Failed to call API"}
    except Exception as e:
        return {"status": 0, "error": str(e)}

@router.get('/checkSmart')
def check_smart():
    if is_service_active("smartsystemsrestapiservice"):
        return {"success": True}
    else:
        return {"success": False}


@router.get('/manageSmart/{mode}')
async def manage_smart(mode):
    restartsmart = False
    restartapi = False

    if int(mode) == 1:
        if is_service_enabled("smartsystemsrestapiservice"):
            if not is_service_active("smartsystemsrestapiservice"):
                ret = sysService("start", "SmartAPI")
                restartapi = ret["success"]
            else:
                restartapi = True
        else:
            ret = sysService("enable", "SmartAPI")
            if ret["success"]:
                ret = sysService("start", "SmartAPI")
                restartapi = ret["success"]

        if restartapi:
            max_attempts = 30  # ìµœëŒ€ 15ì´ˆ (30 * 0.5ì´ˆ)
            for i in range(max_attempts):
                if await checkSmartAPI_active():
                    logging.debug(f"âœ… SmartAPI ready after {i * 0.5:.1f}s")
                    break

                if i == max_attempts - 1:
                    logging.warning("âš ï¸ SmartAPI start timeout")
                    return {
                        "api": False,
                        "smart": restartsmart,
                        "success": False,  # â­ ì¶”ê°€
                        "message": "Service started but not responding"
                    }

                await asyncio.sleep(0.5)
            if not is_service_enabled("smartsystemsservice"):
                ret = sysService("enable", "SmartSystems")
                restartsmart = ret["success"]
    else:  # mode == 0
        if service_exists("smartsystemsservice.service"):
            if is_service_enabled("smartsystemsrestapiservice"):
                if is_service_active("smartsystemsrestapiservice"):
                    ret = sysService("stop", "SmartAPI")
                    restartapi = ret["success"]
                sysService("disable", "SmartAPI")

            if is_service_enabled("smartsystemsservice"):
                if is_service_active("smartsystemsservice"):
                    ret = sysService("stop", "SmartSystems")
                    restartsmart = ret["success"]
                sysService("disable", "SmartSystems")

    return {
        "api": restartapi,
        "smart": restartsmart,
        "success": True  # â­ ì¶”ê°€ (ì •ìƒ ì™„ë£Œ)
    }


async def checkSmartAPI_active():
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"http://{os_spec.restip}:5000/api/alive",
                timeout=1.0
            )
            return response.status_code == 200
    except:
        return False

@router.get('/restartasset')  # save setup.json
async def restartasset():
    # redis_state.client.select(0)
    if redis_state.client.hexists("Service","setting"):
        checkflag = redis_state.client.hget("Service","setting")
        if int(checkflag) == 1:
            return {"status": "0","success": False, "error": "Modbus setting is activated"}
    try:
        # redis_state.client.hset("Service","save",1)
        # redis_state.client.hset("Service", "restart", 1)
        if is_service_active("smartsystemsrestapiservice"):
            async with httpx.AsyncClient(timeout=setting_timeout) as client:
                response = await client.get(f"http://{os_spec.restip}:5000/api/isServiceRestartNeeded")
                data = response.json()
                # if response.status_code in [400, 401, 500]:
                #     flag = await checkLoginAPI(request)
                #     if not flag:
                #         return {"success": False, "error": "Restful API Login Failed"}
                #     else:
                #         response = await client.get(f"http://{os_spec.restip}:5000/api/isServiceRestartNeeded")
                #         data = response.json()
            if data['ServiceRestartRequired']:
                return {"status": "1", "success": True}
            else:
                return {"status": "1", "success": False}
        else:
            return {"status": "0", "success": False, "error": "RestfulAPI Service is not running"}
    except Exception as e:
        print("Error:", e)
        return {"status": "0", "success": False, "error": "Redis Error"}

# @router.get('/restartdevice')
# def restartdevice():
#     redis_state.client.select(0)
#     if redis_state.client.hexists("Service", "setting"):
#         checkflag = redis_state.client.hget("Service", "setting")
#         if int(checkflag) == 1:
#             return {"success": False, "error": "Modbus setting is activated"}
#     try:
#         redis_state.client.hset("Service", "save", 1)
#         redis_state.client.hset("Service", "restart", 1)
#         return {"success": True}
#     except Exception as e:
#         return {"success": False, "error": "Redis Error"}

@router.get('/restartdevice')
async def restartdevice(timeout: int = 30):
    # redis_state.client.select(0)

    if redis_state.client.hexists("Service", "setting"):
        checkflag = redis_state.client.hget("Service", "setting")
        if int(checkflag) == 1:
            return {"success": False, "error": "Modbus setting is activated"}

    if redis_state.client.hexists("Equipment", "applyStatus"):
        applyst = redis_state.client.hget("Equipment", "applyStatus")
        applycontext = json.loads(applyst)
        applycontext["restartFW"] = True
        redis_state.client.hset("Equipment", "applyStatus", json.dumps(applycontext))
    else:
        applycontext = { "restartFW":True, "commisionAsset":{}}
        redis_state.client.hset("Equipment", "applyStatus", json.dumps(applycontext))
    try:
        redis_state.client.hset("Service", "save", 1)
        redis_state.client.hset("Service", "restart", 1)

        # save = 0 ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        for _ in range(timeout * 10):  # 0.1ì´ˆ ê°„ê²©
            await asyncio.sleep(0.1)

            save_flag = redis_state.client.hget("Service", "save")
            if save_flag is not None and int(save_flag) == 0:
                return {"success": True, "message": "Restart completed"}

        return {"success": False, "error": f"Timeout ({timeout}s) - save flag not cleared"}

    except Exception as e:
        return {"success": False, "error": f"Redis Error: {str(e)}"}

@router.get('/restartCore')
def restart_core():
    # redis_state.client.select(0)
    if redis_state.client.hexists("Service", "setting"):
        checkflag = redis_state.client.hget("Service", "setting")
        if int(checkflag) == 1:
            return {"success": False, "error": "Modbus setting is activated"}
    try:
        redis_state.client.hset("Service", "restart", 1)
        return {"success": True}
    except Exception as e:
        return {"success": False, "error": "Redis Error"}

@router.post('/restoreSetting') #restore setup.json
def restore_setting():
    if redis_state.client.hexists("Service","setting"):
        checkflag = redis_state.client.hget("Service","setting")
        if int(checkflag) == 1:
            return {"status": "0", "error": "Modbus setting is activated"}

    setting_file = os.path.join(SETTING_FOLDER, 'setup.json')
    backup_file = os.path.join(SETTING_FOLDER, 'setup_backup.json')

    # ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(backup_file):
        return JSONResponse(status_code=400, content={"passOK": "0", "error": "setting_backup.json not found"})

    try:
        # ë°±ì—… íŒŒì¼ì„ setup.jsonìœ¼ë¡œ ë®ì–´ì“°ê¸°
        shutil.copy(backup_file, setting_file)
        with open(backup_file, "r", encoding="utf-8") as f:
            setting = json.load(f)
        # redis_state.client.execute_command("SELECT", 0)
        redis_state.client.hset("System", "setup", json.dumps(setting))
        redis_state.client.hset("Service", "save", 1)
        redis_state.client.hset("Service", "restart", 1)
        return {"passOK": "1", "message": "Restore successful"}
    except Exception as e:
        return JSONResponse(status_code=500, content={"passOK": "0", "error": f"Error occurred while restoring: {str(e)}"})


def get_Bearing(filename):
    _, ext = os.path.splitext(filename)

    if ext.lower() != ".csv":
        return json.loads(filename)
    else:
        parsed_result = []
        with open(filename, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                # ë¬¸ìì—´ â†’ float ë³€í™˜ (Nameì€ ê·¸ëŒ€ë¡œ)
                for key in row:
                    if key != "Name":
                        row[key] = float(row[key])
                parsed_result.append(row)
        return parsed_result

@router.get("/getAssetConfig/{asset}")  #Setting Vue : get Asset info
async def get_assetconfig(asset, request:Request):
    # response = await  http_state.client.get(f"/getNameplate?name="+asset)
    # data = response.json()
    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getNameplate?name="+asset)
        data = response.json()
    #     if response.status_code in [400, 401, 500]:
    #         flag = await checkLoginAPI(request)
    #         if not flag:
    #             return {"success": False, "error": "Restful API Login Failed"}
    #         else:
    #             response = await client.get(f"http://{os_spec.restip}:5000/api/getNameplate?name={asset}")
    #             data = response.json()
    #     superlist = set_structNameplate(data)
    if len(data) > 0:
        return {"success": True, "data": data}
    else:
        return {"success": False, "error": "No Data"}


@router.post("/checkAssetConfig/{asset}")
async def check_assetconfig(asset: str, request: Request):
    data = await request.json()
    if not data:
        return {"status": "0", "error": "No data provided"}

    try:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(
                f"http://{os_spec.restip}:5000/api/checkNameplate?name={asset}",
                json=data
            )
            result = response.json()

        # âœ… ì‘ë‹µ ì²´í¬
        if 'resetRequired' in result:
            return {"status": "1", "success": True, "result": result['resetRequired']}
        else:
            return {"status": "1","success": False, "error": "resetRequired field not found in response"}

    except Exception as e:
        logging.error(str(e))
        return {"status": "0","success": False, "error": str(e)}

# @router.post("/checkAssetConfig/{asset}")
# async def check_assetconfig(asset:str, request:Request):
#     data = await request.json()
#     if not data:
#         return {"status": "0", "error": "No data provided"}
#     try:
#         # response = await  http_state.client.post(f"/checkNameplate?name={asset}", json=data)
#         # result = response.json()
#         async with httpx.AsyncClient(timeout=setting_timeout) as client:
#             response = await client.post(f"http://{os_spec.restip}:5000/api/checkNameplate?name={asset}", json=data)
#             result = response.json()
#         #     if 'status' in result and result['status'] == 500:
#         #         flag = await checkLoginAPI(request)
#         #         if not flag:
#         #             return {"success": False, "error": "Restful API Login Failed"}
#         #         else:
#         #             response = await client.post(f"http://{os_spec.restip}:5000/api/setNameplate?name={asset}", json=data)
#         #             result = response.json()
#     except Exception as e:
#         print("Error:", e)
#         return {"status": "0", "error": str(e)}
#
#     if 'resetRequired' in result:
#         return {"success":True, "result":result['resetRequired']}
#     else:
#         return {"success": False, "error": "No Data"}
    # if len(result) > 0:
    #     return {"success":True, "result":result['resetRequired']}
    # else:
    #     return {"success": False, "error": "No Data"}

@router.post("/setAssetConfig/{asset}")
async def set_assetconfig(asset:str, request:Request):
    data = await request.json()
    if not data:
        return {"status":"1", "success": False, "error": ["No data provided"]}
    try:
        # response = await  http_state.client.post(f"/setNameplate?name={asset}", json=data)
        # result = response.json()
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(f"http://{os_spec.restip}:5000/api/setNameplate?name={asset}", json=data)
            result = response.json()
        #     if 'status' in result and result['status'] == 500:
        #         flag = await checkLoginAPI(request)
        #         if not flag:
        #             return {"success": False, "error": "Restful API Login Failed"}
        #         else:
        #             response = await client.post(f"http://{os_spec.restip}:5000/api/setNameplate?name={asset}", json=data)
        #             result = response.json()
    except Exception as e:
        print("Error:", e)
        return {"status": "0", "error": [str(e)]}

    if result:
        if result["Status"] == 0:
            return {"status":"1","success": True}
        else:
            return {"status":"1","success": False, "error": result["Messages"]}
    else:
        return {"status":"1","success": False, "error": ["Save failed in setNameplate API"]}

@router.get("/getAssetParams/{asset}")  #Setting Vue : get Asset info
async def get_assetParams(asset, request:Request):
    # response = await  http_state.client.get(f"/getParameters?name="+asset)
    # data = response.json()
    async with httpx.AsyncClient(timeout=setting_timeout) as client:
        response = await client.get(f"http://{os_spec.restip}:5000/api/getParameters?name="+asset)
        data = response.json()
    #     if response.status_code in [400, 401, 500]:
    #         flag = await checkLoginAPI(request)
    #         if not flag:
    #             return {"success": False, "error": "Restful API Login Failed"}
    #         else:
    #             response = await client.get(f"http://{os_spec.restip}:5000/api/getParameters?name={asset}")
    #             data = response.json()
    if len(data) > 0:
        return {"success": True, "data": data }
    else:
        return {"success": False, "error": "No Data"}

@router.post("/setAssetParams/{asset}")
async def set_assetParams(asset:str, request:Request):
    data = await request.json()
    if not data:
        return {"status":"1","success": False, "error": ["No data provided"]}
    try:
        # response = await  http_state.client.post(f"/setParameters?name={asset}", json=data)
        # result = response.json()
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.post(f"http://{os_spec.restip}:5000/api/setParameters?name={asset}", json=data)
            result = response.json()
        #     if 'status' in result and result['status'] == 500:
        #         flag = await checkLoginAPI(request)
        #         if not flag:
        #             return {"success": False, "error": "Restful API Login Failed"}
        #         else:
        #             response = await client.post(f"http://{os_spec.restip}:5000/api/setParameters?name={asset}", json=data)
        #             result = response.json()
    except Exception as e:
        print("Error:", e)
        return {"status":"0", "success": False, "error": [str(e)]}

    if result:
        if result["Status"] == 0:
            return {"status":"1", "success": True}
        else:
            return {"status":"1", "success": False, "error": result["Messages"]}
    else:
        return {"status":"1", "success": False, "error": ["Save failed in setParameters API"]}

@router.get("/test/{channel}/{asset}") 
async def test_asset(channel, asset):
    test_timeout = httpx.Timeout(
        connect=2.0,  # ì—°ê²°ì—ëŠ” 5ì´ˆ
        read=60.0,  # ì‘ë‹µ ì½ê¸°ëŠ” 2ì´ˆ
        write=2.0,  # ìš”ì²­ ì „ì†¡ì€ 5ì´ˆ
        pool=5.0  # ì—°ê²° í’€ì€ 5ì´ˆ
    )

    try:
        async with httpx.AsyncClient(timeout=test_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/getComm?name={asset}")
            data = response.json()

        result = dict()
        result["AssetName"] = data["AssetName"]
        result["SerialNumber"] = data["SerialNumber"]
        result["Channel"] = data["Channel"]
        result["Commissions"] = data["Commissions"]

        # if redis_state.client.hexists("Equipment","applyStatus"):
        #     applyst = redis_state.client.hget("Equipment","applyStatus")
        #     applycontext = json.loads(applyst)
        #     if applycontext["commisionAsset"][channel]["Name"] == asset:
        #         if len(result["Commissions"]) > 0:
        #             applycontext["commisionAsset"][channel]["result"] = False
        #         else:
        #             applycontext["commisionAsset"][channel]["result"] = True

        #     redis_state.client.hset("Equipment", "applyStatus", json.dumps(applycontext))

        if len(data) > 0:
            return {"success": True, "data": result}
        else:
            return {"success": False, "error": "No Data"}
    except Exception as e:
        print(f"Exception: {type(e).__name__}: {e}")
        return {"success": False, "error": "No Data"}

@router.get("/testwave/{asset}")
async def test_wave(asset, request:Request):
    try:
        # HTTP í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
        # if http_state.error:
        #     return {"success": False, "error": http_state.error}
        #
        # # í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        # client = http_state.client
        # if not client:
        #     return {"success": False, "error": "HTTP client not initialized"}
        #
        # response = await http_state.client.get(f"/getWaveform?name={asset}")
        # data = response.json()
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/getWaveform?name={asset}")
            data = response.json()

        if len(data) > 0:
            waveTDict = dict()
            waveTDict["SR"] = data["SR"]
            waveTDict["Duration"] = data["Duration"]
            waveTDict["Vwave"] = data["Vwave"]
            waveTDict["Iwave"] = data["Iwave"]
            waveTDict["Vfft"] = data["Vfft"]
            waveTDict["Ifft"] = data["Ifft"]
            return {"success": True, "waveT": waveTDict}
        else:
            return {"success": False, "error": "No Data"}
    except Exception as e:
        print(f"Exception: {type(e).__name__}: {e}")
        return {"success": False, "error": "No Data"}

def service_exists(name):
    """ì„œë¹„ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    try:
        result = subprocess.run(
            ['systemctl', 'list-unit-files', name],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=2
        )
        return name in result.stdout
    except:
        return False

def is_service_enabled(name):
    """ì„œë¹„ìŠ¤ ë¶€íŒ… ì‹œ ìë™ ì‹œì‘ ì—¬ë¶€ í™•ì¸ (enabled/disabled)"""
    try:
        result = subprocess.run(['systemctl', 'is-enabled', name],
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE,
                                text=True,
                                timeout=2)
        return result.stdout.strip() == "enabled"
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ enabled ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {name} - {e}")
        return False


@router.get("/checkSmartStatus")
async def check_SmartStatus():
    try:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/status")
            data = response.json()

            return {"success": True, "data":data}
        # data = {
        #     "State": "Stop",
        #     "Message": "Smart Systems RestAPI Service is successfully initialized and running",
        #     "ServiceStartTime": "2025-11-13T03:22:48.2809239+09:00",
        #     "RunTimeErrors": ["Corrupted smart systems files.","No asset defined in smart system."]
        # }
        # return {"success": True, "data": data}
    except Exception as e:
        return {"success": False, "msg":str(e)}

def is_same_version(current: str, new: str) -> bool:
    """ë‘ ë²„ì „ì´ ê°™ì€ì§€"""
    return tuple(map(int, new.split('.'))) == tuple(map(int, current.split('.')))

async def check_SmartVersion():
    try:
        async with httpx.AsyncClient(timeout=setting_timeout) as client:
            response = await client.get(f"http://{os_spec.restip}:5000/api/version")
            data = response.json()
            # short_version = '.'.join(data["Version"].split('.')[:3])
            return {"success": True, "Version":data["Version"]}

    except Exception as e:
        return {"success": False, "Version": "1.0.3"}

def check_a35version():
    # redis_state.client.select(0)
    if not redis_state.client.exists("version"):
        return None
    fw = redis_state.client.hget("version","fw")
    a35 = redis_state.client.hget("version","a35")

    return {"fw":fw , "A35":a35}

@router.post('/uploadCerts')
def upload_certs(files: List[UploadFile] = File(...)):
    """AWS IoT Core ì¸ì¦ì„œ íŒŒì¼ë“¤ ì—…ë¡œë“œ (ë³µìˆ˜)"""
    if not files:
        return {'passOK': 0, 'error': 'No files provided'}

    allowed_extensions = {'.pem', '.crt', '.key', '.cert'}
    save_path = os.path.join(SETTING_FOLDER, "certs")
    os.makedirs(save_path, exist_ok=True)

    uploaded = []
    errors = []

    for file in files:
        if file.filename == '':
            continue

        file_ext = os.path.splitext(file.filename)[1].lower()
        if file_ext not in allowed_extensions:
            errors.append({'filename': file.filename, 'error': 'Invalid file type'})
            continue

        try:
            file_path = os.path.join(save_path, file.filename)
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)

            os.chmod(file_path, 0o600)
            uploaded.append(file.filename)

        except Exception as e:
            errors.append({'filename': file.filename, 'error': str(e)})

    return {
        'passOK': 1 if uploaded else 0,
        'uploaded': uploaded,
        'errors': errors
    }


@router.get('/listCerts')
def list_certs():
    """ì €ì¥ëœ ì¸ì¦ì„œ íŒŒì¼ ëª©ë¡"""
    cert_path = os.path.join(SETTING_FOLDER, "certs")

    if not os.path.exists(cert_path):
        return {'passOK': 1, 'files': []}

    files = []
    for f in os.listdir(cert_path):
        file_path = os.path.join(cert_path, f)
        if os.path.isfile(file_path):
            files.append({
                'filename': f,
                'size': os.path.getsize(file_path),
                'modified': os.path.getmtime(file_path)
            })

    return {'passOK': 1, 'files': files}

@router.delete('/deleteCert/{filename}')
def delete_cert(filename: str):
    """ì¸ì¦ì„œ íŒŒì¼ ì‚­ì œ"""
    # ê²½ë¡œ ì¡°ì‘ ë°©ì§€
    if '..' in filename or '/' in filename:
        return {'passOK': 0, 'error': 'Invalid filename'}

    file_path = os.path.join(SETTING_FOLDER, "certs", filename)

    if not os.path.exists(file_path):
        return {'passOK': 0, 'error': 'File not found'}

    try:
        os.remove(file_path)
        return {'passOK': 1, 'filename': filename}
    except Exception as e:
        return {'passOK': 0, 'error': str(e)}

@router.get("/checkMQTT")
def check_mqtt():
    if redis_state.client.hexists("System", "setup"):
        setup = json.loads(redis_state.client.hget("System", "setup"))
    else:
        file_path = os.path.join(SETTING_FOLDER, 'setup.json')
        if not os.path.exists(file_path):
            return {"passOK": 0, "error": "setting file not found"}
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                setup = json.load(f)
        except Exception as e:
            return {"passOK": 0}

    ret = {}
    if setup:
        if "MQTT" in setup["General"]:
            if int(setup["General"]["MQTT"]["Use"]) == 1:
                if service_exists("mqClient"):
                    if is_service_enabled("mqClient"):
                        if not is_service_active("mqClient"):
                            ret["start"] = execService("start","mqClient",0.3)
                    else:
                        ret["enable"] = execService("enable", "mqClient",0.5)
                        ret["start"] = execService("start", "mqClient")
                else:
                    ret["service"] = create_service_file("mqClient","MQTT Client","/home/root/mqClient/mqtt_client","/home/root/mqClient")
                    ret["reload"] = execService("daemon-reload", None, 0.5)  # ì´ê±° ì¶”ê°€!
                    ret["enable"] = execService("enable", "mqClient",0.5)
                    ret["start"] = execService("start", "mqClient",0.3)
            else:
                if service_exists("mqClient"):
                    if is_service_enabled("mqClient"):
                        if is_service_active("mqClient"):
                            ret["stop"] = execService("stop", "mqClient",0)
                        ret["disable"] = execService("disable", "mqClient",0)
    return {"passOK":1, "result": ret}

def create_service_file(
        service_name: str,
        description: str,
        exec_start: str,
        working_directory: str,
        user: str = "root",
        after: str = "network.target",
        restart: str = "always",
        wanted_by: str = "multi-user.target"
) -> bool:
    """systemd ì„œë¹„ìŠ¤ íŒŒì¼ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤."""

    service_content = f"""[Unit]
Description={description}
After={after}

[Service]
ExecStart={exec_start}
WorkingDirectory={working_directory}
Restart={restart}
User={user}

[Install]
WantedBy={wanted_by}
"""
    filename = f"/etc/systemd/system/{service_name}.service"
    try:
        with open(filename, 'w') as f:
            f.write(service_content)
        return True
    except Exception as e:
        print(str(e))
        return False

def execService(cmd: str, item: str = None, wait_after: float = 0) -> dict:
    """
    systemctl ëª…ë ¹ ì‹¤í–‰

    Args:
        cmd: systemctl ëª…ë ¹ (start, stop, enable, disable, daemon-reload ë“±)
        item: ì„œë¹„ìŠ¤ ì´ë¦„ (daemon-reloadì˜ ê²½ìš° None)
        wait_after: ëª…ë ¹ ì‹¤í–‰ í›„ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    """
    try:
        if cmd == "daemon-reload":
            command = ['sudo', 'systemctl', 'daemon-reload']
        else:
            if not item:
                return {
                    'success': False,
                    'error': f'Service name required for {cmd}',
                    'action': cmd
                }
            command = ['sudo', 'systemctl', cmd, item]

        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=30
        )

        # ì„±ê³µ ì‹œ ëŒ€ê¸°
        if result.returncode == 0 and wait_after > 0:
            time.sleep(wait_after)

        return {
            'success': result.returncode == 0,
            'stdout': result.stdout.strip(),
            'stderr': result.stderr.strip(),
            'returncode': result.returncode,
            'service': item,
            'action': cmd
        }

    except subprocess.TimeoutExpired:
        return {
            'success': False,
            'error': f'Timeout expired while {cmd}ing {item or "daemon"}',
            'service': item,
            'action': cmd
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'service': item,
            'action': cmd
        }

@router.get("/SysCheck")
async def check_sysStatus():
    data = {}

    if os_spec.os == 'Windows':
        if not redis_state.client is None:
            # redis_state.client.execute_command("SELECT", 0)
            if redis_state.client.hexists("System", "Status"):
                data = json.loads(redis_state.client.hget("System", "Status"))
        data["core"] = 0

        usage = psutil.disk_usage('/')
        disk1 = {
            "drive": "/",
            "totalGB": round(usage.total / (1024 ** 3), 2),
            "freeGB": round(usage.free / (1024 ** 3), 2),
            "status": "ok" if usage.percent < 90 else "warning"
        }

        return {"success": True, "data": data, "disk": [disk1]}
    else:
        version_dict = getVersions()
        key_map = {
            'fw': 'fw',
            'a35': 'A35',
            'web': 'WebServer',
            'core': 'Core',
            'smartsystem': 'SmartSystems'
        }
        versionDict = {}
        if version_dict:
            for src_key, dst_key in key_map.items():
                versionDict[dst_key] = version_dict[src_key]

        apiResult = await check_SmartVersion()

        if apiResult:
            versionDict['SmartSystems'] = apiResult['Version']

        a35Dict = check_a35version()
        if not a35Dict is None:
            versionDict['fw'] = a35Dict['fw']
            versionDict['A35'] = a35Dict['A35']

        servicedict = {
            'smartsystem' : 'smartsystemsservice',
            'smartapi': 'smartsystemsrestapiservice',
            'redis': 'redis',
            'influxdb': 'influxdb',
            'core': 'core',
            'webserver':'webserver',
            'a35':'sv500A35'
        }
        service_status = {}

        # ê° ì„œë¹„ìŠ¤ì˜ ìƒíƒœ í™•ì¸
        for key, service_name in servicedict.items():
            service_status[key] = is_service_active(service_name)

        usage = psutil.disk_usage('/')
        disk1 = {
            "drive": "/",
            "totalGB": round(usage.total / (1024 ** 3), 2),
            "freeGB": round(usage.free / (1024 ** 3), 2),
            "status": "ok" if usage.percent < 90 else "warning"
        }

        usage = psutil.disk_usage('/usr/local')
        disk2 = {
            "drive": "/usr/local",
            "totalGB": round(usage.total / (1024 ** 3), 2),
            "freeGB": round(usage.free / (1024 ** 3), 2),
            "status": "ok" if usage.percent < 90 else "warning"
        }

        return {"success": True, "data":service_status,  "disk":[disk1, disk2], "versions":versionDict}

@router.get('/SysService/{cmd}/{item}')
def control_service(cmd, item):
    return sysService(cmd, item)

@router.get('/ServiceStatus')
def check_allservice():
    # redis_state.client.select(0)
    devMode = redis_state.client.hget("System", "mode")

    if devMode == 'device0':
        servicedict = {
            'redis': 'redis',
            'influxdb': 'influxdb',
            'core': 'core',
            'webserver': 'webserver',
            'a35':'a35'
        }
    else:
        servicedict = {
            'smartsystem': 'smartsystemsservice',
            'smartapi': 'smartsystemsrestapiservice',
            'redis': 'redis',
            'influxdb': 'influxdb',
            'core': 'core',
            'webserver': 'webserver',
            'a35':'a35',
        }

    service_status = {}

    # ê° ì„œë¹„ìŠ¤ì˜ ìƒíƒœ í™•ì¸
    for key, service_name in servicedict.items():
        service_status[key] = is_service_active(service_name)

    # ìƒíƒœ í™•ì¸
    abnormal = False
    for key, value in service_status.items():
        if not value:  # ì„œë¹„ìŠ¤ê°€ ì£½ì–´ìˆìœ¼ë©´ ë¹„ì •ìƒ
            abnormal = True
            break

    status_list = get_system_status()

    resultDict = {}
    if abnormal:
        resultDict["service"] = False
        resultDict["serviceDict"] = service_status
    else:
        resultDict["service"] = True

    if len(status_list) > 0:
        resultDict["data"] = status_list
        resultDict["system"] = False
    else:
        resultDict["system"] = True

    return resultDict


def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    # CPU ì‚¬ìš©ë¥  (1ì´ˆê°„ ì¸¡ì •)
    cpu_percent = psutil.cpu_percent(interval=1)

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    memory = psutil.virtual_memory()
    memory_percent = memory.percent

    # ë£¨íŠ¸ ë””ë ‰í† ë¦¬(/) ì‚¬ìš©ë¥ 
    disk = psutil.disk_usage('/')
    disk_percent = round((disk.used / disk.total) * 100, 1)

    highList = []
    if memory_percent > 90:
        highList.append('MEMORY')
    if cpu_percent > 90:
        highList.append('CPU')
    if disk_percent > 80:
        highList.append('DISK')

    return highList

@router.post("/command")
async def push_command_left(command: Command, request:Request):
    """ìƒˆë¡œìš´ commandë¥¼ Redis ë¦¬ìŠ¤íŠ¸ì˜ ì™¼ìª½ì— ì¶”ê°€"""
    if command.cmd != 2:
        saveLog(command.get_item_name(), request)
    try:
        binary_data = command_to_binary(command)
        # redis_state.client_db1.select(1)
        redis_state.client_db1.lpush('command', binary_data)

        return {
            "success": True,
            "message": "Command pushed to left of list",
            "data": command.dict()
        }
    except Exception as e:
        return {
            "success": False,
            "message": str(e)
        }


async def wait_for_file(watch_paths: list, timeout: int = 30) -> dict:
    """íŒŒì¼ ìƒì„± ëŒ€ê¸° (IN_CLOSE_WRITE ì´ë²¤íŠ¸ ê°ì‹œ)"""
    result = {path: None for path in watch_paths}
    paths_completed = set()
    event = threading.Event()

    wm = pyinotify.WatchManager()


    class Handler(pyinotify.ProcessEvent):
        def process_IN_CLOSE_WRITE(self, event_data):
            print(f"[DEBUG] íŒŒì¼ ì“°ê¸° ì™„ë£Œ: {event_data.pathname}")
            if event_data.pathname.endswith('.json'):
                # ì–´ëŠ ê°ì‹œ ê²½ë¡œì—ì„œ ìƒì„±ëëŠ”ì§€ ì°¾ê¸°
                for path in watch_paths:
                    if event_data.pathname.startswith(path):  # ê²½ë¡œ í¬í•¨ ì—¬ë¶€ë¡œ ì²´í¬
                        result[path] = event_data.pathname
                        paths_completed.add(path)
                        print(f"[DEBUG] ë§¤ì¹­ ì„±ê³µ! ({len(paths_completed)}/{len(watch_paths)})")
                        if len(paths_completed) == len(watch_paths):
                            event.set()
                        break

    notifier = pyinotify.ThreadedNotifier(wm, Handler())

    for path in watch_paths:
        wm.add_watch(path, pyinotify.IN_CLOSE_WRITE)

    notifier.start()

    try:
        for _ in range(timeout * 10):
            if event.is_set():
                return {"success": True, "files": result}
            await asyncio.sleep(0.1)

        return {"success": False, "message": f"íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)", "files": result}
    finally:
        notifier.stop()

@router.get("/HarmTrigger/{channel}")
async def set_harmTrigger(channel, request:Request, cmd: int = CmdType.CMD_CAPTURE, item: int = ItemType.ITEM_WAVEFORM):
    try:
        if channel == 'Main' or channel == 'main':
            chtype = 0
        else:
            chtype = 1
        await push_command_left(Command(type=chtype, cmd=cmd, item=item), request)
        redis_state.client_db1.hset("waveRequest",channel,1)
        return {"success": True}

    except Exception as e:
        return {"success": False, "message": str(e)}

@router.get("/trigger")
async def trigger_waveform(
        request: Request,
        cmd: int = CmdType.CMD_CAPTURE,
        item: int = ItemType.ITEM_WAVEFORM,
        target: int = 2,
        timeout: int = 90
):
    """ì›¨ì´ë¸Œí¼ íŠ¸ë¦¬ê±° ë° íŒŒì¼ ìƒì„± ëŒ€ê¸°"""
    try:
        # 1. ê°ì‹œ ê²½ë¡œ ê²°ì •
        if target == 2:
            watch_paths = [WAVEFORM_PATHS[0], WAVEFORM_PATHS[1]]
        else:
            watch_paths = [WAVEFORM_PATHS[target]]

        # 2. ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
        for path in watch_paths:
            if os.path.exists(path):
                for filename in os.listdir(path):
                    file_path = os.path.join(path, filename)
                    try:
                        if os.path.isfile(file_path):
                            os.remove(file_path)
                            print(f"[DEBUG] ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {file_path}")
                    except Exception as e:
                        print(f"[WARNING] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}")

        # 3. ê°ì‹œ ìƒíƒœ ì´ˆê¸°í™”
        result = {path: None for path in watch_paths}
        paths_created = {}  # ìƒì„± ê°ì§€ëœ íŒŒì¼ë“¤
        paths_completed = set()  # ì™„ë£Œ ê°ì§€ëœ ê²½ë¡œë“¤
        event = threading.Event()
        wm = pyinotify.WatchManager()

        class Handler(pyinotify.ProcessEvent):
            def process_IN_CREATE(self, event_data):
                """íŒŒì¼ ìƒì„± ì‹œì‘ ê°ì§€"""
                if event_data.pathname.endswith('.json') or event_data.pathname.endswith('.bin'):
                    print(f"[DEBUG] íŒŒì¼ ìƒì„± ì‹œì‘: {event_data.pathname}")
                    for path in watch_paths:
                        if event_data.pathname.startswith(path):
                            paths_created[path] = event_data.pathname
                            print(f"[DEBUG] ìƒì„± ê°ì§€ ({len(paths_created)}/{len(watch_paths)})")
                            break

            def process_IN_CLOSE_WRITE(self, event_data):
                """íŒŒì¼ ì“°ê¸° ì™„ë£Œ ê°ì§€"""
                if event_data.pathname.endswith('.json') or event_data.pathname.endswith('.bin'):
                    print(f"[DEBUG] íŒŒì¼ ì“°ê¸° ì™„ë£Œ: {event_data.pathname}")
                    for path in watch_paths:
                        if event_data.pathname.startswith(path):
                            result[path] = event_data.pathname
                            paths_completed.add(path)
                            print(f"[DEBUG] ì™„ë£Œ ê°ì§€ ({len(paths_completed)}/{len(watch_paths)})")

                            if len(paths_completed) == len(watch_paths):
                                print(f"[DEBUG] ëª¨ë“  íŒŒì¼ ì™„ë£Œ!")
                                event.set()
                            break

        notifier = pyinotify.ThreadedNotifier(wm, Handler())
        for path in watch_paths:
            wm.add_watch(path, pyinotify.IN_CREATE | pyinotify.IN_CLOSE_WRITE)

        notifier.start()

        try:
            # 4. íŠ¸ë¦¬ê±° ì „ì†¡
            if target in [0, 2]:
                await push_command_left(Command(type=0, cmd=cmd, item=item), request)
            if target in [1, 2]:
                await push_command_left(Command(type=1, cmd=cmd, item=item), request)

            print(f"[DEBUG] íŠ¸ë¦¬ê±° ì „ì†¡ ì™„ë£Œ (target={target}), íŒŒì¼ ëŒ€ê¸° ì¤‘...")

            # 5. íŒŒì¼ ìƒì„± ì™„ë£Œ ëŒ€ê¸°
            for _ in range(timeout * 10):
                if event.is_set():
                    return {
                        "success": True,
                        "message": "ì •ìƒ ì™„ë£Œ",
                        "files": result
                    }
                await asyncio.sleep(0.1)

            # 6. íƒ€ì„ì•„ì›ƒ - ìƒì„±ì€ ê°ì§€í–ˆëŠ”ì§€ í™•ì¸
            if len(paths_created) > 0:
                # ìƒì„±ì€ ê°ì§€í–ˆëŠ”ë° ì™„ë£Œë¥¼ ëª» ê°ì§€ = ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ ê°€ì ¸ê°
                print(f"[WARNING] ìƒì„± ê°ì§€í–ˆìœ¼ë‚˜ ì™„ë£Œ ë¯¸ê°ì§€ - ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ íŒŒì¼ ì²˜ë¦¬í•œ ê²ƒìœ¼ë¡œ ì¶”ì •")
                return {
                    "success": True,
                    "message": "íŒŒì¼ ìƒì„± ê°ì§€ (ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ ì²˜ë¦¬)",
                    "files": paths_created,
                    "assumed_taken": True
                }
            else:
                # ìƒì„±ì¡°ì°¨ ê°ì§€ ëª»í•¨ = ì§„ì§œ íƒ€ì„ì•„ì›ƒ
                return {
                    "success": False,
                    "message": f"íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ) - íŒŒì¼ ìƒì„± ê°ì§€ ì‹¤íŒ¨",
                    "files": result
                }

        finally:
            notifier.stop()

    except Exception as e:
        return {"success": False, "message": str(e)}


@router.get('/getMode')
def get_sysMode():
    try:
        # redis_state.client.select(0)
        result = redis_state.client.hget("System","mode")
        return {"success": True, "mode": result}
    except Exception as e:
        print(str(e))
        return {"success": False}


@router.get('/updateSmartSystem/{mode}')
async def update_smartsystem(mode, request: Request):
    if int(mode) == 1:
        c_text = 'Smart System reinstall'
        saveLog("Reinstll SmartSystem", request)
    else:
        c_text = 'Smart System update'
        saveLog("Update SmartSystem", request)
    lastpost = get_lastpost()
    if lastpost["result"] == 1:
        idx = int(lastpost["data"]["id"])
        smartVersion = lastpost["data"]["smart_version"]
        dict = getVersions()
        if smartVersion != dict["smartsystem"]:
            smartVersion = dict["smartsystem"]
        update = Post(title='SW Update', context=c_text, mtype=1, utype='smartsystem',
                      smart_version=smartVersion)
        save_post(update, 1, idx)
    else:
        update = Post(title='SW Install', context='Smart System install', mtype=0, utype='smartsystem',
                      smart_version='1.0.0')
        save_post(update, 0, 0)


    if int(mode) == 1:
        reset_assetInfo('Main','Sub')
        try:
            result = subprocess.run(
                ['sh', '/usr/local/sv500/iss/install.sh', '--fresh'],
                capture_output=True,
                text=True,
                check=True
            )
            service_timeout = 30
            start_time = time.time()

            while time.time() - start_time < service_timeout:
                if check_smart():
                    break
                await asyncio.sleep(1)

            if not check_smart():
                return {"success": False, "message": "Service start timed out"}

            # 2. API í—¬ìŠ¤ì²´í¬ ì¬ì‹œë„ (ìµœëŒ€ 60ì´ˆ)
            health_timeout = 60
            start_time = time.time()

            while time.time() - start_time < health_timeout:
                try:
                    async with httpx.AsyncClient(timeout=5) as client:
                        response = await client.get(f"http://{os_spec.restip}:5000/api/alive")
                        if response.status_code == 200:
                            return {"success": True, "message": "Fresh installation is completed"}
                except Exception as e:
                    print(f"Health check retry... {e}")
                await asyncio.sleep(3)  # 3ì´ˆ ê°„ê²© ì¬ì‹œë„

            return {"success": False, "message": "Health check timed out after 60s"}
        except subprocess.CalledProcessError as e:
            return {"success": False, "message": f"Fresh installation is failed: {e.stderr}"}  # 6. ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
        except subprocess.TimeoutExpired:
            return {"success": False, "message": "Fresh installation is timeout"}

    else:
        try:
            result = subprocess.run(
                ['sh', '/usr/local/sv500/iss/install.sh'],
                capture_output=True,
                text=True,
                check=True
            )
            service_timeout = 30
            start_time = time.time()

            while time.time() - start_time < service_timeout:
                if check_smart():
                    break
                await asyncio.sleep(1)

            if not check_smart():
                return {"success": False, "message": "Service start timed out"}

            # 2. API í—¬ìŠ¤ì²´í¬ ì¬ì‹œë„ (ìµœëŒ€ 60ì´ˆ)
            health_timeout = 60
            start_time = time.time()

            while time.time() - start_time < health_timeout:
                try:
                    async with httpx.AsyncClient(timeout=5) as client:
                        response = await client.get(f"http://{os_spec.restip}:5000/api/alive")
                        if response.status_code == 200:
                            return {"success": True, "message": "Update completed"}
                except Exception as e:
                    print(f"Health check retry... {e}")
                await asyncio.sleep(3)  # 3ì´ˆ ê°„ê²© ì¬ì‹œë„

            return {"success": False, "message": "Health check timed out after 60s"}

        except subprocess.CalledProcessError as e:
            return {"success": False, "message": f"Update failed: {e.stderr}"}
        except Exception as e:
            return {"success": False, "message": str(e)}


def reset_assetInfo(channel1, channel2):
    FILE_PATH = os.path.join(SETTING_FOLDER, "setup.json")

    if redis_state.client.hexists("System", "setup"):
        setting = json.loads(redis_state.client.hget("System", "setup"))
    else:
        if not os.path.exists(FILE_PATH):
            return {"success": False, "error": "setting file not found"}
        try:
            with open(FILE_PATH, "r", encoding="utf-8") as f:
                setting = json.load(f)
        except Exception as e:
            return {"success": False, "error": str(e)}

    # ì±„ë„ë³„ ì—ì…‹ì •ë³´ ë¦¬ì…‹
    if channel1 != '':
        for ch in setting.get("channel", []):
            if ch.get("channel") == "Main":
                ch["assetInfo"] = {
                    "name": "",
                    "type": "",
                    "nickname": "",
                    "driveType": "DOL"
                }
                break

    if channel2 != '':
        for ch in setting.get("channel", []):
            if ch.get("channel") == "Sub":
                ch["assetInfo"] = {
                    "name": "",
                    "type": "",
                    "nickname": "",
                    "driveType": "DOL"
                }
                break

    # ì €ì¥
    with open(FILE_PATH, "w", encoding="utf-8") as f:
        json.dump(setting, f, indent=2, ensure_ascii=False)

    redis_state.client.hset("System", "setup", json.dumps(setting))


@router.post("/setDefaultIP")
async def set_defaultIP(request:Request):
    try:
        data = await request.json()
        default_file_path = os.path.join(SETTING_FOLDER, 'default.json')

        with open(default_file_path, "r", encoding="utf-8") as f:
            defaults = json.load(f)

        defaults["General"]["tcpip"]["ip_address"] = data["ip"]

        with open(default_file_path, "w", encoding="utf-8") as f:
            json.dump(defaults, f, indent=2)  # indent ì¶”ê°€ë¡œ ê°€ë…ì„± í–¥ìƒ

        saveLog("Default IP Change : " + data["ip"], request)
        return {"success": True}
    except Exception as e:
        return {"success" : False}